}
# Run this function with each of the k.
AvgSil(k=i)
# avg_sil will be generated.
# then save it in the table.
# siltable[i-1, 2]  <<-  avg_sil
siltable2[i-1, 2] <<-  i+10
}
siltable[1, 2]
siltable[2, 1]
sillist <- list()
# avg_sil will be generated.
# then save it in the table.
sillist[[i-1]] <- avg_sil
sillist[[1]]
for(i in k.values){
AvgSil <- function(k){
km_res <<- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
avg_sil <<- mean(ss[, 3])
}
# Run this function with each of the k.
AvgSil(k=i)
# avg_sil will be generated.
# then save it in the table.
sillist[[i-1]] <- avg_sil
# siltable[i-1, 2]  <<-  avg_sil
siltable2[i-1, 2] <<-  i+10
}
for(i in k.values){
AvgSil <- function(k){
km_res <<- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
avg_sil <<- mean(ss[, 3])
}
# Run this function with each of the k.
AvgSil(k=i)
# avg_sil will be generated.
# then save it in the table.
sillist[[i-1]] <- avg_sil
# siltable[i-1, 2]  <<-  avg_sil
# siltable2[i-1, 2] <<-  i+10
}
sillist
AvgSil <- function(k){
km_res <<- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
avg_sil <<- mean(ss[, 3])
}
AvgSil <- function(k){
km_res <<- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
avg_sil <<- mean(ss[, 3])
}
for(i in k.values){
# Run this function with each of the k.
AvgSil(k=i)
# avg_sil will be generated.
# then save it in the table.
sillist[[i-1]] <- avg_sil
# siltable[i-1, 2]  <<-  avg_sil
# siltable2[i-1, 2] <<-  i+10
}
sillist
for(i in 2:15){
# Run this function with each of the k.
AvgSil(k=i)
# avg_sil will be generated.
# then save it in the table.
sillist[[i-1]] <- avg_sil
# siltable[i-1, 2]  <<-  avg_sil
# siltable2[i-1, 2] <<-  i+10
}
sillist
siltable
apply(siltable, MARGIN=1, FUN = sum)
siltable[, 1]
apply(siltable[, 1], MARGIN=1, FUN = sum)
apply(na.omit(siltable), MARGIN=1, FUN = sum)
apply(siltable, MARGIN=1, FUN = sum)
siltable  <- data.frame(K=k.values, K2=k.values, Avg_Silhouette=NA)
siltable
apply(siltable, MARGIN=1, FUN = sum)
siltable3  <- data.frame(K=k.values, K2=k.values)
siltable3
apply(siltable3, MARGIN=1, FUN = sum)
tapply(siltable3, MARGIN=1, FUN = sum)
lapply(siltable3, MARGIN=1, FUN = sum)
siltable3  <- data.frame(K=k.values)
lapply(siltable3, MARGIN=1, FUN = sum)
siltable3
AvgSil(k=2)
avg_sil
AvgSil(k=3)
avg_sil
AvgSil(k=2)
ss
lapply(siltable3, MARGIN=1, FUN = AvgSil)
apply(siltable3, MARGIN=1, FUN = sum)
apply(siltable3, MARGIN=1, FUN = AvgSil)
siltable3
AvgSil <- function(k){
km_res <<- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
siltable3  <- data.frame(K=k.values)
siltable3
apply(siltable3, MARGIN=1, FUN = AvgSil)
avg_sil <- function(k) {
km.res <- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
avg_sil_values <- purrr::map_dbl(k.values, avg_sil)
is(avg_sil_values)
avg_sil_values
siltable3  <- matrix(K=k.values)
siltable3  <- matrix(k.values, ncol=1)
siltable3
apply(siltable3, MARGIN=1, FUN = AvgSil)
apply(siltable3, MARGIN=1, FUN = AvgSil)
apply(siltable3, MARGIN=1, FUN = AvgSil)
AvgSil(k=2)
AvgSil(k=3)
AvgSil(k=4)
AvgSil <- function(k){
km_res <<- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
AvgSil(k=4)
avg_sil_values <- purrr::map_dbl(k.values, avg_sil)
avg_sil_values
avg_sil(k=4)
avg_sil <- function(k) {
km.res <- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
apply(siltable3, MARGIN=1, FUN = avg_sil)
siltable3  <- data.frame(K=k.values)
apply(siltable3, MARGIN=1, FUN = avg_sil)
resultvec <- apply(siltable3, MARGIN=1, FUN = avg_sil)
length(resultvec)
siltable3$Avg_Silhouette <- resultvec
siltable3
avg_sil_values
# Name your main directory for future use.
main.wd <- file.path(getwd())
# Import source code to run the analyses to follow.
source("lib/load_and_check.R")
source("lib/prep_data.R")
# ---------------------------------------------------------------------------------------------------------------
# Load example totals data
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/dietstudy/")
# Load the totals.csv
totals <- read.table("Totals_to_use.txt",  sep = "\t", header = T)
# Load your metadata if you have one.
metadata <- read.csv("Metadata_1.csv", header=T)
# Come back to the main directory
setwd(main.wd)
# Show which has "yes" in the "Remove" column, and remove them.
RemoveRows(data = totals, metadata.file = metadata)
# ---------------------------------------------------------------------------------------------------------------
# If taking average by each category (user or other treatment(s))
# Specify the data to be used, category to group by, and the range of columns (variables)
# to calculate the means of each variables
# Nutrients analysis  --> start.col = "PROT",    end.col = "B12_ADD"
AverageBy(data = totals_selected, by = "UserName", start.col = "PROT", end.col = "B12_ADD")
# Results are saved in this dataframe.  Probably too large to see as is.
meansbycategorydf
# The column names should be the same as start.col-end.col.
colnames(meansbycategorydf)
# The row names should be each category entry to calculate means for.
rownames(meansbycategorydf)
# pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = meansbycategorydf)
# pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = meansbycategorydf)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <-  subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variabels in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim(selected_variables)
# ---------------------------------------------------------------------------------------------------------------
# Define your input file. Need to scale it to accommodate measurements in different units.
colnames(selected_variables)
kmeans_input <- scale(selected_variables) # correlated variables removed.
theme_set(theme_bw(base_size = 14))
# ---------------------------------------------------------------------------------------------------------------
# Use the elbow method to find the ideal K.
ElbowMethod(k.values = 1:15)
# Function to do the Elbow method.
ElbowMethod <- function(k.values=1:15){
set.seed(123)
# Define a function to compute total within-cluster sum of square
wss <- function(k, data) {
kmeans(data, k, nstart = 25)$tot.withinss
}
# extract wss for 2-15 clusters
wsstable <- data.frame(K=k.values, WithinClusterSS=NA)
for(i in k.values){
wssvalue <- wss(k.values[i], data = kmeans_input)
wsstable[i, 2] <- wssvalue
}
# create a wss value plot
ggplot(wsstable, aes(x = K, y = WithinClusterSS)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = 1:nrow(wsstable)) +
labs(x = "Number of clusters K",
y = "Total within-clusters sum of squares") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
}
# ---------------------------------------------------------------------------------------------------------------
# Use the elbow method to find the ideal K.
ElbowMethod(k.values = 1:15)
avg_sil <- function(k) {
km.res <- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
# avg_sil_values <- purrr::map_dbl(k.values, avg_sil)
# avg_sil_values
# OR
siltable3  <- data.frame(K=k.values)
# Compute and plot wss for k = 2 to k = 15
k.values <- 2:15
# ---------------------------------------------------------------------------------------------------------------
# Find the ideal k: the Silhouette method
# need the cluster package
library(cluster)
avg_sil <- function(k) {
km.res <- kmeans(kmeans_input, centers=k, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
# avg_sil_values <- purrr::map_dbl(k.values, avg_sil)
# avg_sil_values
# OR
siltable3  <- data.frame(K=k.values)
resultvec <- apply(siltable3, MARGIN=1, FUN = avg_sil)
siltable3$Avg_Silhouette <- resultvec
siltable3
ggplot(siltable3, aes(x = K, y = Avg_Silhouette)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = 1:nrow(siltable3)) +
labs(x = "Number of clusters K",
y = "Average Silhouettes") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
# Or use factoextra package to use the silhouette method to identify the optimum K.
factoextra::fviz_nbclust(kmeans_input, kmeans, method="silhouette")
ggplot(siltable3, aes(x = K, y = Avg_Silhouette)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = 1:nrow(siltable3)) +
labs(x = "Number of clusters K",
y = "Average Silhouettes") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
siltable3
ggplot(siltable3, aes(x = K, y = Avg_Silhouette)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = 1:nrow(siltable3)-1) +
labs(x = "Number of clusters K",
y = "Average Silhouettes") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
ggplot(siltable3, aes(x = K, y = Avg_Silhouette)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = siltable3$K) +
labs(x = "Number of clusters K",
y = "Average Silhouettes") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
# Or use factoextra package to use the silhouette method to identify the optimum K.
factoextra::fviz_nbclust(kmeans_input, kmeans, method="silhouette")
SilhouetteMethod <- function(k=2:15){
# need the cluster package
library(cluster)
# Define avg_sil function first.
avg_sil <- function(number){
km.res <- kmeans(kmeans_input, centers=number, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
# Create a dataframe with k values.
siltable3  <- data.frame(K=k.values)
# Apply avg_sil function to each of the K and save results as a vector.
resultvec <- apply(siltable3, MARGIN=1, FUN = avg_sil)
# Save the result vector as a new column of siltable.
siltable3$Avg_Silhouette <- resultvec
# Plot K and the Silhouette values.
ggplot(siltable3, aes(x = K, y = Avg_Silhouette)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = siltable3$K) +
labs(x = "Number of clusters K",
y = "Average Silhouettes") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
# The K with the max average Silhouette value is the ideal K.
}
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.
SilhouetteMethod(k.values = 2:15)
SilhouetteMethod <- function(k.values = 2:15){
# need the cluster package
library(cluster)
# Define avg_sil function first.
avg_sil <- function(number){
km.res <- kmeans(kmeans_input, centers=number, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
# Create a dataframe with k values.
siltable3  <- data.frame(K=k.values)
# Apply avg_sil function to each of the K and save results as a vector.
resultvec <- apply(siltable3, MARGIN=1, FUN = avg_sil)
# Save the result vector as a new column of siltable.
siltable3$Avg_Silhouette <- resultvec
# Plot K and the Silhouette values.
ggplot(siltable3, aes(x = K, y = Avg_Silhouette)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = siltable3$K) +
labs(x = "Number of clusters K",
y = "Average Silhouettes") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
# The K with the max average Silhouette value is the ideal K.
}
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.
SilhouetteMethod(k.values = 2:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.
SilhouetteMethod(k.values = 2:15)
# or use the factoextra package to find the ideal K.
factoextra::fviz_nbclust(kmeans_input, kmeans, method="silhouette")
GapMethod <- function(k.values=1:15){
# Calculate the gap statistic.
library(cluster)
gap_stat <- clusGap(kmeans_input, FUN = kmeans, nstart = 25,
K.max = k.values[length(k.values)],
B=50) # B is the number of bootstrapping
# Print the result.
print(gap_stat, method = "firstmax")
# Convert the table to a dataframe first.
gap_stat_df <- as.data.frame(gap_stat[1])
# Add the number of clusters as a new column.
gap_stat_df$NumberofK <- k.values
# Plot the gap statistic with ggplot2
require(ggplot2)
ggplot(gap_stat_df, aes(x=NumberofK, y=Tab.gap)) +
geom_line() +
geom_point() +
geom_errorbar(aes(ymin=Tab.gap-Tab.SE.sim,
ymax=Tab.gap+Tab.SE.sim),
width=0.2,
position=position_dodge(0.05)) +
scale_x_continuous(breaks = 1:nrow(gap_stat_df)) +
labs(x = "Number of clusters K",
y = "Gap stastistic") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
# The highest K is the optimum K.
}
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
GapMethod(k.values = 1:15)
# or use the factoextra package to use the Gap statistic method.
factoextra::fviz_gap_stat(gap_stat)
# or use the factoextra package to use the Gap statistic method.
factoextra::fviz_gap_stat(gap_stat)
# or use factoextra package.
gap_stat <- clusGap(kmeans_input, FUN = kmeans, nstart = 25,
K.max = k.values[length(k.values)],
B=50) # B is the number of bootstrapping
factoextra::fviz_gap_stat(gap_stat)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
GapMethod(k.values = 1:15)
factoextra::fviz_gap_stat(gap_stat)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
GapMethod(k.values = 1:15)
FactoextraGapMethod <- function(k.values = 1:15){
library(cluster)
# Calculate Gap statistics first.
gap_stat <- clusGap(kmeans_input, FUN = kmeans, nstart = 25,
K.max = k.values[length(k.values)],
B=50) # B is the number of bootstrapping
# Print the result.
print(gap_stat, method = "firstmax")
# Visualize. The best K is marked with a dotted line.
factoextra::fviz_gap_stat(gap_stat)
}
# or use the factoextra package to use the Gap statistic method.
FactoextraGapMethod(k.values = 1:15)
# or use the factoextra package to use the Gap statistic method.
FactoextraGapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
GapMethod(k.values = 1:15)
gap_stat
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
GapMethod(k.values = 1:15)
# or use the factoextra package to use the Gap statistic method.
FactoextraGapMethod(k.values = 1:15)
# or use the factoextra package to use the Gap statistic method.
FactoextraGapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
GapMethod(k.values = 1:15)
GapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
GapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
GapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
GapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
# or use the factoextra package to use the Gap statistic method.
FactoextraGapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
# or use the factoextra package to use the Gap statistic method.
FactoextraGapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
# or use the factoextra package to use the Gap statistic method.
FactoextraGapMethod(k.values = 1:15)
factoextra::fviz_cluster(km.results,
data = kmeans_input,
ellipse = T, ellipse.alpha = 0.1,
ggtheme = theme_bw(base_size = 10),
repel = F, labelsize = 10)
# ========================================================================================
# The optimum k should have been identified by now.
#  Do the k-means analysis with your optimum k.
# ========================================================================================
# ---------------------------------------------------------------------------------------------------------------
# Perform the k-means analysis, with the optimum number you found above as the 'centers'.
km.results <- kmeans(x=kmeans_input, centers = 15, nstart = 25)
factoextra::fviz_cluster(km.results,
data = kmeans_input,
ellipse = T, ellipse.alpha = 0.1,
ggtheme = theme_bw(base_size = 10),
repel = F, labelsize = 10)
# Calculate the means of each variable for each cluster.
aggregate(kmeans_input, by=list(cluster = km.results$cluster), mean)
# Add the cluster assignment to the original data.
totals_cl <- cbind(totals, cluster = km.results$cluster)
# Filter for a particular cluster.
library(dplyr)
mysubset <- as.data.frame(totals_cl) %>% filter(cluster==13)
# Add the cluster assignment to the original data.
totals_cl <- cbind(totals, cluster = km.results$cluster)

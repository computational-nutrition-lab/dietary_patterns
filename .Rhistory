# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# Freq table with 2 variables.===========================================================
mydata = read.table(file="clipboard", sep="\t") # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
as.data.frame(table(mydata$V1))
V1table = as.data.frame(table(mydata$V1))
write.table(V1table, "clipboard", sep="\t")
write.table(V1table, "clipboard", sep="\t", row.names = F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
write.table(bbb, "clipboard", sep="\t", row.names = F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
# mycol
bbb = as.data.frame(table(mycol))
bbb
write.table(bbb, "clipboard", sep="\t", row.names = F)
# use this working directory until this script is complete.
setwd("~/GitHub/dietary_patterns")
# Name your main directory for future use.
main.wd <- file.path(getwd())
# ========================================================================================
# Load source scripts
# ========================================================================================
source("lib/Food_tree_scripts/newick.tree.r")
source("lib/Food_tree_scripts/check.db.r")
source("lib/Food_tree_scripts/format.foods.r")
source("lib/Food_tree_scripts/filter.db.by.diet.records.r")
source("lib/Food_tree_scripts/make.food.tree.r")
source("lib/Food_tree_scripts/make.food.otu.r")
source("lib/Food_tree_scripts/make.fiber.otu.r")
source("lib/Food_tree_scripts/make.dhydrt.otu.r")
library(SASxport)
# read in SAS data for 2011-2012 dietary intake
# food1 <- read.xport("data/NHANES/DR1IFF_G.XPT")
food1 <- read.xport("E:/MSU OneDrive 20210829/UMinn/20_NHANES/2015-16/Data/Interview_IndFoods_Day1_DR1IFF_I.XPT")
# food2 <- read.xport("data/NHANES/DR2IFF_G.XPT")
food2 <- read.xport("E:/MSU OneDrive 20210829/UMinn/20_NHANES/2015-16/Data/Interview_IndFoods_Day2_DR2IFF_I.XPT")
# tots1 <- read.xport("data/NHANES/DR1TOT_G.XPT")
tots1 <- read.xport("E:/MSU OneDrive 20210829/UMinn/20_NHANES/2015-16/Data/Total_Nutrient_Day1_DR1TOT_J.XPT")
# tots2 <- read.xport("data/NHANES/DR2TOT_G.XPT")
tots2 <- read.xport("E:/MSU OneDrive 20210829/UMinn/20_NHANES/2015-16/Data/Total_Nutrient_Day2_DR2TOT_J.XPT")
# demo <- read.xport("data/NHANES/DEMO_G.XPT")
demo <- read.xport("eg_data/NHANES/DEMO_I.XPT")
adults <- demo[demo$ridageyr >= 18,]
# read in food description files
# foodcodes <- sasxport.get("data/NHANES/DRXFCD_G.XPT")
foodcodes <- read.xport("eg_data/NHANES/FoodCodes_DRXFCD_I.XPT")
# Quality filtering
# did the food recall meet the minimum criteria to be considered reliable?
food1 <- food1[food1$dr1drstz == 1,] # this drops people with unreliable records and breastfed children
food2 <- food2[food2$dr2drstz == 1,]
# fix nameing for downstream food tree use
# names(food1)[names(food1) == "dr1ifdcd"] <- "FoodCode"
names(food1)[names(food1) == "DR1IFDCD"] <- "FoodCode"
# Use the only the 50 datapoints.
totals_QCed_sampled <- read.table("results/PCA_results/temporary/eg 50/total_d12_mean_QC500_2_input_PCs_50.txt", sep="\t", header=T)
# Use the only the 50 datapoints.
totals_QCed_sampled <- read.table("results/PCA_results/temporary/eg 50 inc GRMS KCAL MOIS/total_d12_mean_QC500_2_input_PCs_50.txt", sep="\t", header=T)
dim(totals_QCed_sampled)
aaa <- totals_QCed_sampled[, -"KCAL"]
aaa <- totals_QCed_sampled[, "KCAL"]
aaa <- totals_QCed_sampled[, -"KCAL"]
# ***** Remove GRMS, KCAL, MOIS, NoOfItems ****** IMPORTANT!
drops <- c("KCAL","GRMS", "MOIS", "NoOfItems")
drops
dim(aaa)
aaa <- totals_QCed_sampled[ , !(names(totals_QCed_sampled) %in% drops)]
dim(aaa)
colnames(aaa)
# Define the input data to be used.
input_data <- totals_QCed_sampled
colnames(input_data)
dim(input_data)
colnames(aaa)
dim(aaa)
# Define the input data to be used.
input_data <- totals_QCed_sampled
colnames(input_data)
# Use the only the 50 datapoints.
totals_QCed_sampled <- read.table("results/PCA_results/temporary/eg 50 inc GRMS KCAL MOIS/total_d12_mean_QC500_2_input_PCs_50.txt", sep="\t", header=T)
dim(totals_QCed_sampled)
# ***** Remove GRMS, KCAL, MOIS, NoOfItems ****** IMPORTANT!
drops <- c("KCAL","GRMS", "MOIS", "NoOfItems")
# Drop only the columns whose names are in the drop vector.
aaa <- totals_QCed_sampled[ , !(names(totals_QCed_sampled) %in% drops)]
dim(aaa)
colnames(aaa)
# Save it as totals_QCed_sampled.
totals_QCed_sampled <- aaa
dim(totals_QCed_sampled)
# Define the input data to be used.
input_data <- totals_QCed_sampled
dim(input_data)
colnames(input_data)
# The columns specified as start.col, end.col, and all columns in between will be selected.
SubsetColumns(data=input_data, start.col="PROT", end.col="P226")
source("lib/prep_data_for_clustering.R")
source("lib/PCA.R")
# The columns specified as start.col, end.col, and all columns in between will be selected.
SubsetColumns(data=input_data, start.col="PROT", end.col="P226")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
dim(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim(selected_variables)
# ---------------------------------------------------------------------------------------------------------------
# Save the variables after removing correlated variables
write.table(selected_variables,
"results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_rv.txt",
sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation.
SaveCorrMatrix(x=cc,
out.fn="results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_corr_mat.txt")
# ---------------------------------------------------------------------------------------------------------------
# Your input data should be a data frame with variables with non-zero variance.
pca_input <- selected_variables
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Create a scree plot.
screep <- LineScreePlot(pca.data = pca_input, pca.result = scaled_pca)
screep
ggsave("results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_screep.pdf", screep, device="pdf", width=5, height=5, units="in")
# A biplot with the individuals labeled.
biplotlabeled <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label = T)
biplotlabeled
library(ggplot2)
theme_set(theme_bw(base_size = 14))
screep
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
biplotdots <- BiplotDots(pca.result = scaled_pca, pca.data = pca_input, alpha = 0.5)
biplotdots
ggsave("results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_biplotdots.pdf", biplotdots, device="pdf", width=5, height=5, units="in")
# A biplot with the individuals labeled.
biplotlabeled <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label = T)
biplotlabeled
ggsave("results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_biplotlabeled.pdf", biplotlabeled, device="pdf", width=5, height=5, units="in")
# A biplot with the individuals labeled without the variables' arrows.
biplotlabeledwoarrows <- BiplotLabeledwoArrows(pca.result=scaled_pca, pca.data=pca_input,
individuals.label=T)
biplotlabeledwoarrows #+coord_cartesian(xlim=c(-0.1, 0.1), ylim=c(0.05, 0.1))
# A biplot with the individuals labeled without the variables' arrows.
biplotlabeledwoarrows <- BiplotLabeledwoArrows(pca.result=scaled_pca, pca.data=pca_input,
individuals.label=T)
biplotlabeledwoarrows #+coord_cartesian(xlim=c(-0.1, 0.1), ylim=c(0.05, 0.1))
ggsave("results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_biplotlabeledwoarrows.pdf", biplotlabeledwoarrows, device="pdf", width=5, height=5, units="in")
# Plot the directions of the variables.
directions <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=F)
directions
ggsave("results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_directions.pdf", directions, device="pdf", width=5, height=5, units="in")
# Plot the contribution of the variables to a given PC.
LoadingsPlot(pca.result=scaled_pca,  whichPC="PC1",
positive.color="green2", negative.color="grey70", sort.variables = T)
loadings_plot
ggsave("results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_loadings_PC1.pdf", loadings_plot, device="pdf", width=8, height=4.8, units="in")
# Plot the contribution of the variables to a given PC.
LoadingsPlot(pca.result=scaled_pca,  whichPC="PC2",
positive.color="green2", negative.color="grey70", sort.variables = T)
loadings_plot
ggsave("results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_loadings_PC2.pdf", loadings_plot, device="pdf", width=8, height=4.8, units="in")
# ---------------------------------------------------------------------------------------------------------------
# Save the variance explained by each PC as a .txt file.
# Change the file name as necessary.
SaveVarExplained(pca.data = pca_input, pca.result = scaled_pca,
out.fn = "results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_PC_var_explained.txt")
# ---------------------------------------------------------------------------------------------------------------
# Calculate loadings of each PC to the variables and
# save it as a .txt file in the results folder.
# Change the file name as necessary.
SaveLoadings(pca.result=scaled_pca,
out.fn="results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_PC_loadings.txt")
# ---------------------------------------------------------------------------------------------------------------
# Save the PC values with the input which has the metadata and food codes, food names.
# Input is your food input file before any prep for clustering, from which you derived the input for the PCA.
SaveInputAndPCs(input = "results/PCA_results/temporary/eg 50 inc GRMS KCAL MOIS/total_d12_mean_QC500_2_input_PCs_50.txt",
pca.results = scaled_pca,
out.fn = "results/PCA_results/temporary/eg 50 exc GRMS KCAL MOIS/total_d12_mean_QC500_2_50_exc_input_PCs.txt")
source("lib/k-means.R")
# ---------------------------------------------------------------------------------------------------------------
# Define your input file. Need to scale it to accommodate measurements in different units.
colnames(selected_variables)
kmeans_input <- scale(selected_variables) # correlated variables removed.
# Set your ggplot2 theme.
require(ggplot2)
theme_set(theme_bw(base_size = 14))
# ---------------------------------------------------------------------------------------------------------------
# Use the elbow method to find the ideal K.
ElbowMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# or use the factoextra package to use the Silhouette method.
factoextra::fviz_nbclust(kmeans_input, kmeans, method="silhouette")
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# or use the factoextra package to use the Silhouette method.
factoextra::fviz_nbclust(kmeans_input, kmeans, method="silhouette")
# ---------------------------------------------------------------------------------------------------------------
# Use the Gap statistic method to find the ideal K.
set.seed(123)
GapMethod(k.values = 1:15)
GapMethod(k.values = 1:15)
FactoextraGapMethod(k.values = 1:15)
FactoextraGapMethod(k.values = 1:15)
FactoextraGapMethod(k.values = 1:15)
FactoextraGapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Perform k-means analysis with multiple (2-4) Ks, and plot them in one window.
MultipleK(myKs = c(2,3,4,5))
# ---------------------------------------------------------------------------------------------------------------
# Perform k-means analysis with one specified k.
One_K(myK = 5)
dim(totals_QCed_sampled)
dim(input_data)
PC12 = write.table("clipboard", sep="\t", col.names=T)
head(PC12)
PC12 = write.table("clipboard", sep="\t", col.names=T)
head(PC12)
PC12 = read.table("clipboard", sep="\t", col.names=T)
PC12 = read.table("clipboard", sep="\t", header=T)
head(PC12)
groupinfo <- read.table("clipboard", sep = "\t", header = T)
head(groupinfo)
group_PC12 <- cbind(groupinfo, PC12)
head(group_PC12)
tail(group_PC12)
ggplot2(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group))+
geom_point()
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group))+
geom_point()
tail(group_PC12)
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text()
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust=1)
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust=-1)
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust=-0.9)
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust= -0.5)
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust= -0.5) +
theme(legend.position = "bottom")
fillcolor = c("darkred", "orange", "darkgreen", "darkblue", "purple")
colcolor = c("darkred", "orange", "darkgreen", "darkblue", "purple")
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust= -0.5) +
scale_fill_manual(values=fillcolor) +
scale_color_manual(values=colcolor) +
theme(legend.position = "bottom")
fillcolor = c("darkred", "orange", "darkgreen", "darkblue", "violet")
colcolor = c("darkred", "orange", "darkgreen", "darkblue", "violet")
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust= -0.5) +
scale_fill_manual(values=fillcolor) +
scale_color_manual(values=colcolor) +
theme(legend.position = "bottom")
fillcolor = c("darkred", "orange", "darkgreen", "darkblue", "deepviolet")
colcolor = c("darkred", "orange", "darkgreen", "darkblue", "deepviolet")
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust= -0.5) +
scale_fill_manual(values=fillcolor) +
scale_color_manual(values=colcolor) +
theme(legend.position = "bottom")
fillcolor = c("darkred", "orange", "darkgreen", "darkblue", "violet3")
colcolor = c("darkred", "orange", "darkgreen", "darkblue", "violet3")
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust= -0.5) +
scale_fill_manual(values=fillcolor) +
scale_color_manual(values=colcolor) +
theme(legend.position = "bottom")
fillcolor = c("darkred", "orange", "darkgreen", "darkblue", "darkviolet")
colcolor = c("darkred", "orange", "darkgreen", "darkblue", "darkviolet")
ggplot(data=group_PC12, aes(x=PC1, y=PC2, fill=Group, color=Group, label=NewNo_1_50))+
geom_point() +
geom_text(vjust= -0.5) +
scale_fill_manual(values=fillcolor) +
scale_color_manual(values=colcolor) +
theme(legend.position = "bottom")
colnames(totals_QCed_sampled)
# Load the saved food items file.
Food_D1 <- read.table("eg_data/NHANES/Interview_IndFoods_Day1_DR1IFF_I_d.txt", sep="\t", header=T)
# Add the food items information, too.
# Load FPED15-16.
FPED <- read.table("eg_data/NHANES/FPED/FPED_1516_forR.txt", sep="\t", header=T)
# Add the food items information, too.
# Load FPED15-16.
FPED <- read.table("eg_data/NHANES/FPED/FPED_1516_forR.txt", sep="\t", header=T)
head(FPED)
dim(FPED)
head(Food_D1)
identical(Food_D1$Food_code, Food_D1$Food_codeint)
Food_D1$Food_code[1]
# row 1
pickedrow <- Food_D1[1, ]
pickedrow$Food_code
head(FPED)
colnames(FPED)[1] <- "Food_code"
colnames(FPED)
merge(x=pickedrow, y=FPED, by="Food_code", all.x = T)
# merge pickedrow and the item in the FPED with the applicable food code.
pickedrow_fdcat <- merge(x=pickedrow, y=FPED, by="Food_code", all.x = T)
# Look for a row in FPED that contains the food_code in pickedrow.
FPED[FPED$Food_code == pickedrow$Food_code]
# Look for a row in FPED that contains the food_code in pickedrow.
FPED[FPED$Food_code == pickedrow$Food_code, ]
# row 1
pickedrow <- Food_D1[2, ] # observation No.2.
pickedrow
# row 1
pickedrow <- Food_D1[14, ] # observation No.2.
pickedrow
# row 1
pickedrow <- Food_D1[15, ] # observation No.2.
pickedrow
# Look for a row in FPED that contains the food_code in pickedrow.
pickedFPED <- FPED[FPED$Food_code == pickedrow$Food_code, ]
pickedFPED
pickedrow$DR1IGRMS
# GRMS x each food category.
quantity <- pickedrow$DR1IGRMS
quantity * pickedFPED[, -1]
quantity * pickedFPED[, -1]/100
quantity
# GRMS x each food category --> cup or servings of that food in that particular amount.
cup_oz <- quantity * pickedFPED[, -1]/100  # "-1" is to exclude food_code from multiplication.
pickedrow
cbind(pickedrow, cup_oz)
# Join pickedrow and cup_oz, which is the categorized food items converted to cup or oz.
newrow <- cbind(pickedrow, cup_oz)
Food_D1_fc <- as.data.frame()
Food_D1_fc <- data.frame()
Food_D1_fc
Food_D1_fc[15, ] <- newrow
Food_D1_fc
nrow(Food_D1)
Food_D1_fc <- data.frame(No=seq(1,nrow(Food_D1)))
head(Food_D1_fc)
is(newrow)
newrow[1, ]
Food_D1_fc[15, ] <- newrow[1, ]
Food_D1_fc[15, ] <- newrow

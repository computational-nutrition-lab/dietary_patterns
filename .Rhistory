# Save the p-value
pairwise_p["Middlesburg_Valhaarts"] <- Middlesburg_Valhaarts_test[['aov.tab']][["Pr(>F)"]][1]
pairwise_p
adjustedp_FDR <- p.adjust(pairwise_p, method = "fdr")
write.table(adjustedp_FDR, "clipboard", sep = "\t")
# WD
# setwd("~/GitHub/R_Toolbox/Adonis_raw_data-0.3")
setwd("E:/MSU OneDrive 20210829/PIC Cassoulet/PIC/By country WO Morogoro/adonis_delineation")
# Load data
# metadata <- read_excel(path="schubert.metadata.xlsx")
metadata <- read.table("../TASSEL_NJ/By_country_ind_wo_Morogoro_annotation.txt", sep="\t", header=T)
colnames(metadata) <- c("sample_id", "country")  # We want to inner_join or merge by sample_id later.
head(metadata)
table(metadata$country)
# Let's look at the graphic first. Testing diarrheal, C.difficile positive, and healthy individuals.
# Read nmds (ordination?) results. This file contains axes 1-2 of ordination results.
# I think it used 'Bray' method for ordination.
nmds <- read.csv("../TASSEL_PCA/6PC_PIC_pl_geno999_by_country_WO_Mor_het25_mi80_maf3.csv", header=T)
colnames(nmds)[1] <- "sample_id" # We want to inner_join or merge by sample_id later.
head(nmds)
# inner-join and make disease_stat as a factor.
metadata_nmds <- inner_join(metadata, nmds, by="sample_id") %>%
mutate(country = factor(country,
levels=c("Puerto Rico",
"South_Africa",
"Tanzania",
"Washington")
)
)
# ---------------------------------------------------------------------------------------------------------------
# Eigenvalues (% var explained)
eigen <- read.csv("../TASSEL_PCA/Eigenvalues_PIC_pl_geno999_by_country_WO_Mor_het25_mi80_maf3.csv", header=T)
head(eigen)
PercentvarbyPC1 <- round(eigen[1,3]*100, 1)
PercentvarbyPC2 <- round(eigen[2,3]*100, 1)
# Country_fill_colors <- c("#DF536B", # dark pink
#                          "#61D04F", # grass green
#                          "#2297E6", # sunny sky
#                           # "#F5C710", # mustard
#                          "#purple3") # purple
country_fill_col <- c("#FEE4E2", # light pink
"#E5EFCC", # light green
"#CCF2F3", # light blue
"#F6EAFF") # light purple
country_outline_col <- c("#F87D75", #  pink
"#ADCC61", #  green
"#34CCD0", #  blue
"#CA82FF") #  purple
# ---------------------------------------------------------------------------------------------------------------
# Load the distance matrix without the first row (that has the number of samples)
# need to supply the distance matrix
distance <- read.table("../TASSEL_Dist/Dist_mat_PIC_pl_geno999_by_country_WO_Mor_het25_mi80_maf3_f.txt",sep="\t")
head(distance, 1)
dim(distance)
colnames(distance)
# Change the first column name as 'sample_id'.
colnames(distance)[1] <- "sample_id"
head(distance$sample_id, 1)
# make the 1st column (sample_id) as the rownames
rownames(distance) <- distance$sample_id
head(distance, 1)
# Then, make the column names as "sample_id" and the genotype names, which are the rownames.
colnames(distance) <- c("sample_id", rownames(distance))
head(colnames(distance), 10)
# Join distance and metadata so that we pick up only the metadata of samples that are in the distance matrix.
meta_distance <- inner_join( metadata, distance, by="sample_id")
head(meta_distance, 1)
dim(meta_distance)
all_dist <- meta_distance %>%
select(all_of(.[['sample_id']])) %>%   # A period indicates the dataframe that's flowing through the pipeline.
as.dist()  # turn into a distance matrix.
head(all_dist, 3)
colnames(all_dist) # it's a matrix, so it doesn't have colnames.
permutations=10000
# ---------------------------------------------------------------------------------------------------------------
# Run adnis
set.seed(19760620)
# Run adonis with disease_stat as the explanatory variable.
all_test <- adonis(formula = all_dist ~ country,
data=meta_distance,
permulations=permulations)
# USEFUL!
# P value is output$element$sub-element
all_test$aov.tab$`Pr(>F)`[1]
# ---------------------------------------------------------------------------------------------------------------
# What are the factors called?
meta_distance %>% count(country)
table(meta_distance$country)
# ---------------------------------------------------------------------------------------------------------------
# SA vs TZ
# first, filter out only the two from meta_distance.
SA_TZ <- meta_distance %>%
filter(country == "South_Africa" | country == "Tanzania")
# Subset a distance matrix with only the individuals in SA_TZ
SA_TZ_dist <- SA_TZ %>%
select(all_of(.[['sample_id']])) %>%
as.dist()
# Run adonis
SA_TZ_test <- adonis(SA_TZ_dist ~ country,
data= SA_TZ,
permutations=permutations)
SA_TZ_test
# Store the p-value
pairwise_p["SA_TZ_p"] <- SA_TZ_test[['aov.tab']][["Pr(>F)"]][1]
pairwise_p
# Let's plot just SA-TZ.
# Pick up just SA and TZ.
SA_TZ_PC12 <-  metadata_nmds %>%
filter(country == "South_Africa" | country == "Tanzania")
# Plot just the SA and TZ.
SA_TZ_PC12plot <- ggplot(SA_TZ_PC12,
aes(x=PC1, y=PC2, color=country, fill=country)) +
stat_ellipse(geom="polygon", type="norm", level=0.75, alpha=0.3, show.legend=T) +
geom_point(show.legend = F) +
labs(x= paste0("PC1 (", PercentvarbyPC1, "%)"),
y= paste0("PC2 (", PercentvarbyPC2, "%)")) +
scale_x_continuous(limits = c(-30, 21), breaks= round( seq(from=-30, to=21, by=10), 0 ) ) +
scale_y_continuous(limits = c(-30, 21), breaks= round( seq(from=-30, to=21, by=10), 0 ) ) +
theme_bw(base_size = 14) +
scale_color_manual(values = country_outline_col[2:3]) +
scale_fill_manual(values = country_fill_col[2:3]) +
theme(
legend.key.size = unit(0.3, "cm"),
legend.position = c(0.15, 0.15),
legend.background = element_rect(fill="white"),
legend.margin = margin(t=-2, r=3, b=3, l=3),
plot.margin = margin(l=1, r=4, unit='lines'),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
aspect.ratio = 1,
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0) ),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0) ),
plot.caption = element_text(hjust = 0))
# Plot just the SA and TZ.
SA_TZ_PC12plot <- ggplot(SA_TZ_PC12,
aes(x=PC1, y=PC2, color=country, fill=country)) +
stat_ellipse(geom="polygon", type="norm", level=0.75, alpha=0.3, show.legend=T) +
geom_point(show.legend = F) +
labs(x= paste0("PC1 (", PercentvarbyPC1, "%)"),
y= paste0("PC2 (", PercentvarbyPC2, "%)")) +
scale_x_continuous(limits = c(-30, 21), breaks= round( seq(from=-30, to=21, by=10), 0 ) ) +
scale_y_continuous(limits = c(-30, 21), breaks= round( seq(from=-30, to=21, by=10), 0 ) ) +
theme_bw(base_size = 14) +
scale_color_manual(values = country_outline_col[2:3], labels=c("South Africa", "Tanzania")) +
scale_fill_manual(values = country_fill_col[2:3], labels=c("South Africa", "Tanzania")) +
theme(
legend.key.size = unit(0.3, "cm"),
legend.position = c(0.15, 0.15),
legend.background = element_rect(fill="white"),
legend.margin = margin(t=-2, r=3, b=3, l=3),
plot.margin = margin(l=1, r=4, unit='lines'),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
aspect.ratio = 1,
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0) ),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0) ),
plot.caption = element_text(hjust = 0))
SA_TZ_PC12plot
# ---------------------------------------------------------------------------------------------------------------
# SA vs WA
# first, filter out only the two from meta_distance.
SA_WA <- meta_distance %>%
filter(country == "South_Africa" | country == "Washington")
# Subset a distance matrix with only the individuals in SA_WA
SA_WA_dist <- SA_WA %>%
select(all_of(.[['sample_id']])) %>%
as.dist()
# Run adonis
SA_WA_test <- adonis(SA_WA_dist ~ country,
data= SA_WA,
permutations=permutations)
SA_WA_test
# SA and WA have the largest p-value. Let's plot.
# Pick up just SA and WA.
SA_WA_PC12 <-  metadata_nmds %>%
filter(country == "South_Africa" | country == "Washington")
# Plot just the SA and WA.
SA_WA_PC12plot <- ggplot(SA_WA_PC12,
aes(x=PC1, y=PC2, color=country, fill=country)) +
stat_ellipse(geom="polygon", type="norm", level=0.75, alpha=0.3, show.legend=T) +
geom_point(show.legend = F) +
labs(x= paste0("PC1 (", PercentvarbyPC1, "%)"),
y= paste0("PC2 (", PercentvarbyPC2, "%)")) +
scale_x_continuous(limits = c(-30, 21), breaks= round( seq(from=-30, to=21, by=10), 0 ) ) +
scale_y_continuous(limits = c(-30, 21), breaks= round( seq(from=-30, to=21, by=10), 0 ) ) +
theme_bw(base_size = 14) +
scale_color_manual(values = country_outline_col[c(2,4)], labels=c("South Africa", "Washington")) +
scale_fill_manual(values =  country_fill_col[c(2,4)], labels=c("South Africa", "Washington")) +
theme(
legend.key.size = unit(0.3, "cm"),
legend.position = c(0.15, 0.15),
legend.background = element_rect(fill="white"),
legend.margin = margin(t=-2, r=3, b=3, l=3),
plot.margin = margin(l=1, r=4, unit='lines'),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
aspect.ratio = 1,
axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0) ),
axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0) ),
plot.caption = element_text(hjust = 0))
SA_WA_PC12plot
ggsave("PIC384_SA_WA_elipse075.tif",  SA_WA_PC12plot, device='tiff', dpi=150, width=5.88, height=4.99)
# Load necessary packages.
library(SASxport)
# Set where the NHANES data and food code table are.
# it is not in the eg_data folder because it's too large to save in GitHub folder.
# setwd("E:/MSU OneDrive 20210829/UMinn/20_NHANES/2015-16")
setwd("~/GitHub/dietary_patterns")
# Load necessary functions.
source("lib/load_clean_NHANES.R")
# Format the food table and save it as a .txt file.
PrepareFoodCodeTable(raw.food.code.table = "eg_data/NHANES/FoodCodes_DRXFCD_I.XPT",
out.fn =              "eg_data/NHANES/FoodCodes_DRXFCD_I_f.txt")
# Load the formatted food code table.
foodcodetable_f <- read.table("eg_data/NHANES/FoodCodes_DRXFCD_I_f.txt", sep="\t", header=T)
# ---------------------------------------------------------------------------------------------------------------
# Import items data Day 1, add food item descriptions, and save it as a txt file.
# LIKELY IT WILL BE A HUGE FILE.
ImportNHANESFoodItems(data.name="E:/MSU OneDrive 20210829/UMinn/20_NHANES/2015-16/Data/Interview_IndFoods_Day1_DR1IFF_I.XPT",
food.code.column = "DR1IFDCD",
food.code.table = foodcodetable_f,
out.fn = "eg_data/NHANES/Interview_IndFoods_Day1_DR1IFF_I_d.txt") # 'd' stands for food descriptions
# Load the saved food items file.
Food_D1 <- read.table("eg_data/NHANES/Interview_IndFoods_Day1_DR1IFF_I_d.txt", sep="\t", header=T)
# Import items data Day 2, add food item descriptions, and save it as a txt file.
ImportNHANESFoodItems(data.name="E:/MSU OneDrive 20210829/UMinn/20_NHANES/2015-16/Data/Interview_IndFoods_Day2_DR2IFF_I.XPT",
food.code.column = "DR2IFDCD",
food.code.table = foodcodetable_f,
out.fn = "eg_data/NHANES/Interview_IndFoods_Day2_DR2IFF_I_d.txt")
# Add food item description and save it as a txt file.
Food_D2 <- read.table("eg_data/NHANES/Interview_IndFoods_Day2_DR2IFF_I_d.txt", sep="\t", header=T)
# Remove children.
# Load the demographics file, then filter by age > 18.
demog <- read.xport("eg_data/NHANES/DEMO_I.XPT")
adults <- demog[demog$RIDAGEYR >= 18, ]
# Code descriptions in Analytic notes: https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DR1IFF_J.htm#Analytic_Notes
food1 <- subset(Food_D1, DR1DRSTZ == 1)
food2 <- subset(Food_D2, DR2DRSTZ == 1)
food1names <- unique(food1$SEQN)
food2names <- unique(food2$SEQN)
keepnames <- food1names[food1names %in% food2names]
keepnames_adults <- keepnames[keepnames %in% adults$SEQN]
# Keep those who reported more than 1 food item per day.
freqtable1 <- as.data.frame(table(food1$SEQN))
freqtable1_m <- freqtable1[freqtable1$Freq > 1, ]
colnames(freqtable1_m)[1] <- "SEQN"
keepnames_adults_mult1 <- keepnames_adults[keepnames_adults %in% freqtable1_m$SEQN]
# Take only the participants whose names are in keepnames_adults_mult1.
food1b <- food1[food1$SEQN %in% keepnames_adults_mult1, ]
# Do the same for food2
freqtable2 <- as.data.frame(table(food2$SEQN))
freqtable2_m <- freqtable2[freqtable2$Freq > 1, ]
colnames(freqtable2_m)[1] <- "SEQN"
keepnames_adults_mult2 <- keepnames_adults[keepnames_adults %in% freqtable2_m$SEQN]
food2b <- food2[food2$SEQN %in% keepnames_adults_mult2, ]
# Create a vector of SEQN of those that have both day 1 and day 2 data.
food1bnames <- unique(food1b$SEQN)
food2bnames <- unique(food2b$SEQN)
keepnames12 <- food1bnames[food1bnames %in% food2bnames]
day1variables <- read.table('eg_data/NHANES/NHANES_Food_VarNames_Day1.txt', header=F)
# Which variables to pick up from the food data
var_to_use1 <- names(food1b) %in% day1variables$V1
# pick up only the specified variables
food1c <- food1b[, var_to_use1]
# Remove "DR1T", "DR1" from the column names
colnames(food1c) <- gsub(colnames(food1c), pattern = "DR1I", replacement = "")
colnames(food1c) <- gsub(colnames(food1c), pattern = "DR1",  replacement = "")
# Check
head(food1c, 1)
day2variables <- read.table('eg_data/NHANES/NHANES_Food_VarNames_Day2.txt', header=F)
var_to_use2 <- names(food2b) %in% day2variables$V1
food2c <- food2b[, var_to_use2]
colnames(food2c) <- gsub(colnames(food2c), pattern = "DR2I", replacement = "")
colnames(food2c) <- gsub(colnames(food2c), pattern = "DR2", replacement = "")
head(food2c, 1)
# Make a day variable before combining
food1c$Day <- 1
food2c$Day <- 2
# Ensure the columns of food1c and food2c match before joining them.
identical(colnames(food1c), colnames(food2c))
# Combine food1 and food2 as a longtable.
food12c <- rbind(food1c, food2c)
# Pick up only the individuals listed in keepnames12.
food12d <- food12c[food12c$SEQN %in% keepnames12, ]
# save the combined and QCed food items as a .txt file. (IT WILL BE A HUGE FILE.)
write.table(food12d, "eg_data/NHANES/NHANES1516_items_d12_QC.txt", sep="\t", quote=F, row.names=F)
# ---------------------------------------------------------------------------------------------------------------
# Take n random samples of participants (SEQN).
RandomSample(data= food12d, n=500, out.fn="eg_data/NHANES/NHANES1516_items_d12_QC_500sampled.txt")
# Calculate total for day 1. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Take only the Day 1 data
food12d_d1 <- subset(food12d, Day==1)
colnames(food12d_d1)
food12d_d1[, 2:67]
# Sum nutrients; this is total data calculated by hand.
first.val <- "GRMS"
seocnd.val <- "P226"
last.val <- "P226"
total1 <- aggregate(food12d_d1[, first.val:last.val], by=list(food12d_d1$SEQN), FUN=sum)
source("lib/prep_data_for_clustering.R")
colnames(food12d_d1)
total1 <- aggregate(food12d_d1[, GRMS], by=list(food12d_d1$SEQN), FUN=sum)
total1 <- aggregate(food12d_d1[, 2:3], by=list(food12d_d1$SEQN), FUN=sum)
head(total1)
start.colnum <- match(first.val, names(food12d_d1))
start.colnum
end.colnum <-   match(last.val, names(food12d_d1))
end.colnum
l_num <- match(first.val, names(food12d_d1))
start_col_num <- match(first.val, names(food12d_d1))
end_col_num <-   match(last.val, names(food12d_d1))
total1 <- aggregate(food12d_d1[, start_col_num:end_col_num], by=list(food12d_d1$SEQN), FUN=sum)
head(total1)
total1$Day <- 1
colnames(total1)[1] <- "SEQN"
# Create a vector of number of food items reported by each participant.
n_items1 <- as.data.frame(table(food12d_d1$SEQN))
colnames(n_items1) <- c("SEQN", "NoOfItems")
# Add it to total1
total1b <- merge(x=total1, y=n_items1, by="SEQN", all.x=T)
# Some checking
subset(total1b, NoOfItems<2) # should be zero.
# Look for any missing data
total1b[is.na(total1b$NoOfItems), ]
# Calculate total for day 2. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
food12d_d2 <- subset(food12d, Day==2)
# Calculate total for day 2. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
food12d_d2 <- subset(food12d, Day==2)
# Sum nutrients.
# First, speicfy the first and the last column (variable) names to calculate totals for.
first.val <- "GRMS"
last.val <- "P226"
start_col_num <- match(first.val, names(food12d_d2))  # The number of column that matches the first variable specified.
end_col_num <-   match(last.val, names(food12d_d2)) # The number of column that matches the last variable specified.
# Sum food items by SEQN from start through end columns.
total2 <- aggregate(food12d_d2[, start_col_num:end_col_num],
by=list(food12d_d2$SEQN),
FUN=sum)
total2$Day <- 2
colnames(total2)[1] <- "SEQN"
# Create a vector of number of food items reported by each participant.
n_items2 <- as.data.frame(table(food12d_d2$SEQN))
colnames(n_items2) <- c("SEQN", "NoOfItems")
# Add it to total1
total2b <- merge(x=total2, y=n_items2, by="SEQN", all.x=T)
# Some checking
subset(total2b, NoOfItems<2) # should be zero.
# Look for any missing data
total2b[is.na(total2b$NoOfItems), ]
# Merge the totals
# Check if all the columnnames match.
identical(colnames(total1b), colnames(total2b))
# Merge
total12c <- rbind(total1b, total2b)
# Save the calculated totals of day 1 and 2 as a txt file.
write.table(total12c, "eg_data/NHANES/NHANES1516_total_d12_new.txt", sep="\t", row.names=F, quote=F)
# Load the calculated totals.
total12d <- read.table("eg_data/NHANES/NHANES1516_total_d12.txt", sep="\t", header=T)
colnames(total12d)
# Take average of Day 1 and Day 2.
# First, speicify the first and the last column (variable) names to calculate means for.
first.val <- "GRMS"
last.val <- "P226"
start_col_num <- match(first.val, names(total12d))  # The number of column that matches the first variable specified.
start_col_num
end_col_num <-   match(last.val,  names(total12d)) # The number of column that matches the last variable specified.
end_col_num
last.val <- "NoOfItems"  #### Now you want the average of No of Items reported, too.
end_col_num <-   match(last.val,  names(total12d)) # The number of column that matches the last variable specified.
end_col_num
# Sum food items by SEQN from start through end columns.
meantotal12a <- aggregate(total12d[, start_col_num:end_col_num],
by=list(total12d$SEQN),
FUN=mean)
# Remove the day, which is now all 1.5 (the average of 1 and 2.)
meantotal12 <- meantotal12a[, !names(meantotal12a) %in% "Day"]
# Change "Group.1" to "SEQN".
colnames(meantotal12)[1] <- "SEQN"
# Save meantotals as a txt file.
write.table(meantotal12, "eg_data/NHANES/NHANES1516_total_d12_mean.txt", sep="\t", row.names=F, quote=F)
# Load the mean total
meantotal12b <- read.table("eg_data/NHANES/NHANES1516_total_d12_mean.txt", sep="\t", header=T)
# ---------------------------------------------------------------------------------------------------------------
# For totals, the same QC can be applied as ASA24 totals QC procedure.
# Functions to clean ASA24 data.
source("lib/load_clean_ASA24.R")
# Define the input data.  This dataframe will be modified after each filter.
QCtotals <- meantotal12b
# ---------------------------------------------------------------------------------------------------------------
# Save QCtotals as a .txt file.
write.table(QCtotals, "eg_data/NHANES/NHANES1516_total_d12_mean_QC.txt", sep="\t", quote=F, row.names=F)
# ---------------------------------------------------------------------------------------------------------------
# Take n random samples of participants (SEQN).
RandomSample(data=QCtotals, n=500, out.fn="eg_data/NHANES/NHANES1516_total_d12_mean_QC_500sampled.txt")
# Import source code to run the analyses to follow.
# source("lib/specify_dir_and_check_col.R")
# source("lib/prep_data_for_clustering.R")
source("lib/PCA.R")
source("lib/k-means.R")
# Load the subsetted totals file.
totals_QCed_sampled <- read.table("eg_data/NHANES/NHANES1516_total_d12_mean_QC_500sampled.txt", sep="\t", header=T)
head(totals_QCed_sampled,2)
hist(totals_QCed_sampled$MOIS)
totals_QCed_sampled$GRMSminusMOIS <- totals_QCed_sampled$GRMS - totals_QCed_sampled$MOIS
plot(totals_QCed_sampled$MOIS, totals_QCed_sampled$GRMS)
# Define the input data to be used.
input_data <- totals_QCed_sampled
# The columns specified as start.col, end.col, and all columns in between will be selected.
SubsetColumns(data=input_data, start.col="GRMS", end.col = "NoOfItems")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim(selected_variables)
# original
head(subsetted_non0var, 1)
ggplot2::theme_set(theme_bw(base_size = 14))
# ========================================================================================
# Perform Principal Component Analysis.
# ========================================================================================
#
# ---------------------------------------------------------------------------------------------------------------
# Name your input data.
# Your input data should be a data frame with variables with non-zero variance.
pca_input <- selected_variables
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Create a scree plot.
screep <- LineScreePlot(pca.data = pca_input, pca.result = scaled_pca)
screep
ggsave("results/PCA_results/temporary/total_d12_mean_QC500_screep.pdf", screep, device="pdf", width=5, height=5, units="in")
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
biplotdots <- BiplotDots(pca.result = scaled_pca, pca.data = pca_input, alpha = 0.5)
biplotdots
ggsave("results/PCA_results/temporary/total_d12_mean_QC500_biplotdots.pdf", biplotdots, device="pdf", width=5, height=5, units="in")
head(totals_QCed_sampled, 2)
hist(totals_QCed_sampled$MOIS)
totals_QCed_sampled$GRMSminusMOIS <- totals_QCed_sampled$GRMS - totals_QCed_sampled$MOIS
plot(totals_QCed_sampled$MOIS, totals_QCed_sampled$GRMS)
hist(totals_QCed_sampled$GRMSminusMOIS)
meantotal12b
# Define the input data.  This dataframe will be modified after each filter.
QCtotals <- meantotal12b
# Flag if KCAL is <600 or >5700 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals,
target.colname = "KCAL", min = 600, max = 5700)
# Flag if PROT is <10 or >240 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals,
target.colname = "PROT", min = 10, max = 240)
# Flag if TFAT is <15 or >230 --> ask remove or not --> if yes, remove those rows
QCOutliers(input.data = QCtotals,
target.colname = "TFAT", min = 15, max = 230)
# ---------------------------------------------------------------------------------------------------------------
# Save QCtotals as a .txt file.
write.table(QCtotals, "eg_data/NHANES/NHANES1516_total_d12_mean_QC_2.txt", sep="\t", quote=F, row.names=F)
# ---------------------------------------------------------------------------------------------------------------
# Take n random samples of participants (SEQN).
RandomSample(data=QCtotals, n=500, out.fn="eg_data/NHANES/NHANES1516_total_d12_mean_QC_2_500sampled.txt")
# Load the subsetted totals file.
totals_QCed_sampled <- read.table(        "eg_data/NHANES/NHANES1516_total_d12_mean_QC_2_500sampled.txt", sep="\t", header=T)
# Load the subsetted totals file.
totals_QCed_sampled <- read.table("eg_data/NHANES/NHANES1516_total_d12_mean_QC_2_500sampled.txt", sep="\t", header=T)
head(totals_QCed_sampled, 2)
hist(totals_QCed_sampled$MOIS)
totals_QCed_sampled$GRMSminusMOIS <- totals_QCed_sampled$GRMS - totals_QCed_sampled$MOIS
plot(totals_QCed_sampled$MOIS, totals_QCed_sampled$GRMS)
hist(totals_QCed_sampled$GRMSminusMOIS)
plot(totals_QCed_sampled$MOIS, totals_QCed_sampled$GRMS)
plot(totals_QCed_sampled$MOIS, totals_QCed_sampled$GRMS)
hist(totals_QCed_sampled$GRMSminusMOIS)
# Define the input data to be used.
input_data <- totals_QCed_sampled
# The columns specified as start.col, end.col, and all columns in between will be selected.
SubsetColumns(data=input_data, start.col="GRMS", end.col = "NoOfItems")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)

tttwoway$Curr_pct <- tttwoway$Current/8*100
tttwoway$Prev_pct <- tttwoway$Previous/4*100
tttwoway$Considered_pct <- tttwoway$Considered/9*100
tttwoway
tttwowaysum = rbind(tttwoway, colSums(tttwoway))
tttwowaysum
rownames(tttwowaysum)[length(rownames(tttwowaysum))] <- "Total"  # Change the last rowname
freqtable <- tttwowaysum[, c(1,4,2,5,3,6)] # change column orders.
write.table(freqtable,"clipboard", sep = "\t")
twoway = table(mydata$`User_status`, mydata$Availability_changed)
twoway
ttwoway = t(twoway)
tttwoway = as.data.frame.matrix(ttwoway)
tttwoway
tttwoway$Curr_pct <- tttwoway$Current/8*100
tttwoway$Prev_pct <- tttwoway$Previous/4*100
tttwoway$Considered_pct <- tttwoway$Considered/9*100
tttwoway
tttwowaysum = rbind(tttwoway, colSums(tttwoway))
tttwowaysum
rownames(tttwowaysum)[length(rownames(tttwowaysum))] <- "Total"  # Change the last rowname
freqtable <- tttwowaysum[, c(1,4,2,5,3,6)] # change column orders.
write.table(freqtable,"clipboard", sep = "\t")
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
sortedbbb = bbb[ order(bbb$Freq, decreasing = T), ]
sortedbbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
sortedbbb = bbb[ order(bbb$Freq, decreasing = T), ]
sortedbbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
write.table(bbb, "clipboard", sep="\t")
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
write.table(bbb, "clipboard", sep="\t")
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
#write.table(mycol, "clipboard", sep="\t")
head(mycol)
nrow(mycol)
# mycol
bbb = as.data.frame(table(mycol))
bbb
library(psych)
install.packages(psych)
install.packages("psych")
library(psych)
Holzinger.9
cor.plot(Holzinger.9,numbers=TRUE)
factanal(factors = 2, covmat = Holzinger.9, n.obs = 145,
rotation = "varimax")
ev <- eigen(Holzinger.9)
ev
fa <- factanal(factors = 2, covmat = Holzinger.9,n.obs = 145,
rotation = "varimax")
cluster.plot(fa)
cluster.plot(fa)
cluster.plot(fa)
# ------------------------------------------------------------------------------------------
# From the agricolae maintainer, Filipe de Mendiburu Delgado, 01/25/2022.
library(agricolae)
data(cotton)
cotton$lineage<-as.factor(cotton$lineage)
cotton$epoca<-as.factor(cotton$epoca)
# Build a mixed effect model with the block effect.
mymodel <- lmer(yield ~ lineage + (1|block), data = cotton)
# Build a mixed effect model with the block effect.
mymodel <- lme4::lmer(yield ~ lineage + (1|block), data = cotton)
out1<-anova(mymodel, type="3", test.statistic= "F")
out1<-agricolae::anova(mymodel, type="3", test.statistic= "F")
out1<-lme4::anova(mymodel, type="3", test.statistic= "F")
out1<-lmerTest::anova(mymodel, type="3", test.statistic= "F")
out1<-emmeans::anova(mymodel, type="3", test.statistic= "F")
# ------------------------------------------------------------------------------------------
# Load packages
library(agricolae)
data(cotton)
library(lm4)
library(lmerTest)
# Build a mixed effect model with the block effect.
mymodel <- lmer(yield ~ lineage + (1|block), data = cotton)
# Show anova table. But this does not show DFerror and MSerror that
# I need for LSD.test.
anova(mymodel,  type="3", test.statistic= "F")
# Build a mixed effect model with the block effect.
mymodel <- lme4::lmer(yield ~ lineage + (1|block), data = cotton)
out1<-emmeans::anova(mymodel, type="3", test.statistic= "F")
out1<-anova(mymodel, type="3", test.statistic= "F")
# Build a mixed effect model with the block effect.
mymodel <- lmer(yield ~ lineage + (1|block), data = cotton)
out1 <- anova(mymodel, type="3", test.statistic= "F")
out1
out2<-summary(mymodel)
out2
View(out2)
out3<-with(cotton, LSD.test(yield, lineage, DFerror, MSerror, console = TRUE))
DFerror <- out1$DenDF
MSerror <- out2$sigma^2
out3<-with(cotton, LSD.test(yield, lineage, DFerror, MSerror, console = TRUE))
install.packages("nlme")
install.packages("nlme")
install.packages("nlme")
install.packages("nlme")
install.packages("nlme")
data(pigs)
agricolae::data(cotton)
data(cotton)
library(agricolae)
data(cotton)
data(pigs)
library(emmeans)
data(pigs)
head(pigs)
head(pigs,10)
table(pigs$source)
table(pigs$percent)
# Use pigs data and build a model
mod3 = nlme::gls(conc ~ source, data = pigs,
weights = varIdent(form = ~1 | source)) # This part
library(gls)
library(nlme)
setwd("E:/MSU OneDrive 20210829/UMinn/20_NHANES")
nhanes1718 <- read.xport("DR1IFF_J.XPT")
# install.packages("SASxport")
require(SASxport)
library(foreign)
nhanes1718 <- read.xport("DR1IFF_J.XPT")
dim(nhanes1718)
# Take the first 450 records.
n450 <- head(nhanes1718, 450)
dim(n450)
# How many participants?
length(unique(n450$SEQN))
boxplot(n450$DR1IKCAL)
library(dplyr)
n450 %>% filter(DR1IFDCD == 94100100) %>% nrow()  # water intake.
water <- n450 %>% filter(DR1IFDCD == 94100100) # water intake record.
hist(water$DR1IGRMS)
summary(water$DR1IGRMS)
water %>% filter(DR1IGRMS > 1000) %>% nrow()
water1L <- water %>% filter(DR1IGRMS > 1000)
water1L[, c("SEQN", "DR1IGRMS")]
# Gram weight of the food/individual component
n450 %>% filter(DR1IGRMS < 500) %>% nrow()/nrow(n450)*100
n450 %>% filter(DR1IGRMS > 1500) %>% nrow()
n450 %>% filter(DR1IGRMS > 1000) %>% nrow()
# Gram weight of the food/individual component
n450 %>% filter(DR1IGRMS < 500) %>% nrow()/nrow(n450)*100
# just remove records that report 500 g or higher intake for now...
# 6.7% of the data will be removed and 93.3% of the data will still be preserved.
n450_a %>% filter(DR1IGRMS < 500)
# just remove records that report 500 g or higher intake for now...
# 6.7% of the data will be removed and 93.3% of the data will still be preserved.
n450_a <- n450 %>% filter(DR1IGRMS < 500)
dim(n450_a)
# See the food codes of 400-500 g
n450_a %>%  arrange(DR1IGRMS) %>% head(DR1IGRMS)
# See the food codes of 400-500 g
n450_a %>%  arrange(DR1IGRMS) %>% head()
# See the food codes of 400-500 g
head(n450_a[ order(n450_a$DR1IGRMS, decreasing = T), ])
# Use this dataset n450_a for now.
# How many records/participants?
table(n450_a$SEQN)
table(n450_a$DR1DAY)
table(n450_a$DR1LANG)
table(n450_a$DR1CCMNM)
table(n450_a$DR1CCMTX)
table(n450_a$DR1_040Z)
foodcodes =  write.table("clipboard", sep = "\t")
foodcodes =  write.table("clipboard", sep = "\t")
foodcodes =  read.table("clipboard", sep = "\t")
foodcodes
foodcodes = read.table("clipboard", sep = "\t")
foodcodes
foodcodes = read.table("clipboard", sep = "\t", header = T)
head(foodcodes)
setwd("~/GitHub/dietary_patterns/lib")
library("C:\Users\sadoh\OneDrive\Documents\GitHub\dietary_patterns\lib\k-means.R")
# ========================================================================================
# Use my prep data, PCA, and k-means functions to analyze this data!
# ========================================================================================
# Load the necessary functions
source("C:\Users\sadoh\OneDrive\Documents\GitHub\dietary_patterns\lib\k-means.R")
source("C:/Users/sadoh/OneDrive/Documents/GitHub/dietary_patterns/lib/k-means.R")
# Take average of each user (n=30) for each of the 64 nutrients.
# Nutrients analysis  --> start.col = "DR1IPROT",    end.col = "DR1IP226"
AverageBy(data = n450_a, by = "SEQN", start.col = "DR1IPROT", end.col = "DR1IP226")
# ========================================================================================
# Use my prep data, PCA, and k-means functions to analyze this data!
# ========================================================================================
# Load the necessary functions
source("C:/Users/sadoh/OneDrive/Documents/GitHub/dietary_patterns/lib/prep_data.R")
source("C:/Users/sadoh/OneDrive/Documents/GitHub/dietary_patterns/lib/PCA.R")
# Take average of each user (n=30) for each of the 64 nutrients.
# Nutrients analysis  --> start.col = "DR1IPROT",    end.col = "DR1IP226"
AverageBy(data = n450_a, by = "SEQN", start.col = "DR1IPROT", end.col = "DR1IP226")
# The column names should be the same as start.col-end.col.
colnames(meansbycategorydf)
# pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = meansbycategorydf)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# original
head(subsetted_non0var, 1)
dim(subsetted_non0var)
# Check to see the name of the original and filtered variables.
# Among the variabels in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim(selected_variables)
ggplot2::theme_set(theme_bw(base_size = 14))
# ========================================================================================
# Perform Principal Component Analysis.
# ========================================================================================
#
# ---------------------------------------------------------------------------------------------------------------
# Specify the plot theme and base font size to use.
library(ggplot2)
ggplot2::theme_set(theme_bw(base_size = 14))
# Name your input data.
# Your input data should be a data frame with variables with non-zero variance.
my_input <- selected_variables
# Perform PCA with the subset data, scaled.
# scaled_pca <- prcomp(x = subsetted_non0var, scale = T)
scaled_pca <- prcomp(x = my_input, scale = T)
# Create a scree plot.
LineScreePlot(pca.data = my_input, pca.result = scaled_pca)
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
BiplotDots(pca.result = scaled_pca, pca.data = my_input)
# Gram weight of the food/individual component
n450 %>% filter(DR1IGRMS > 500) %>% nrow()
# just remove records that report 500 g or higher intake for now...
# 6.7% of the data will be removed and 93.3% of the data will still be preserved.
n450_a <- n450 %>% filter(DR1IGRMS < 500)
dim(n450_a)
# Perform PCA with the subset data, scaled.
# scaled_pca <- prcomp(x = subsetted_non0var, scale = T)
scaled_pca <- prcomp(x = my_input, scale = T)
# Create a scree plot.
LineScreePlot(pca.data = my_input, pca.result = scaled_pca)
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
BiplotDots(pca.result = scaled_pca, pca.data = my_input)
# A biplot with the individuals labeled.
BiplotLabeled(pca.result = scaled_pca,
pca.data = my_input,
individuals.label = TRUE)
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
BiplotDots(pca.result = scaled_pca, pca.data = my_input)
# A biplot with the individuals labeled.
BiplotLabeled(pca.result = scaled_pca,
pca.data = my_input,
individuals.label = TRUE)
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
BiplotDots(pca.result = scaled_pca, pca.data = my_input)
# ---------------------------------------------------------------------------------------------------------------
# Plot %kcal of protein, fat, and carbs.
# need to rename the data so that they will be recognized by the functions..
totals <- n450_a
# ---------------------------------------------------------------------------------------------------------------
# Plot %kcal of protein, fat, and carbs.
# need to rename the data so that they will be recognized by the functions..
totals <- n450_a
totals$UserName <- totals$SEQN
totals$PROT <- totals$DR1IPROT
totals$TFAT <- totals$DR1ITFAT
totals$CARB <- totals$DR1ICARB
totals$SUGR <- totals$DR1ISUGR
head(totals[, c("KCAL", "TFAT", "CARB", "PROT", "SUGR")])
totals$KCAL <- totals$DR1IKCAL
head(totals[, c("KCAL", "TFAT", "CARB", "PROT", "SUGR")])
aaa =head(totals[, c("KCAL", "TFAT", "CARB", "PROT", "SUGR")])
aaa$kcal_prot <- aaa$PROT*4
aaa
aaa$kcal_carb <- aaa$CARB*4
aaa$kcal_tfat <- aaa$TFAT*9
aaa$kcal_total <- aaa$kcal_prot + aaa$kcal_carb + aaa$kcal_tfat
aaa$diff <- aaa$kcal_total - aaa$KCAL
aaa
totals$carb_sugr <- totals$CARB - totals$SUGR
summary(totals$carb_sugr)
# Calculate the mean kcal from carb/protein/fat per participant
CalcKcal()
# ---------------------------------------------------------------------------------------------------------------
# Load necessary functions.
source("C:/Users/sadoh/OneDrive/Documents/GitHub/dietary_patterns/lib/percent_kcal.R")
# Calculate the mean kcal from carb/protein/fat per participant
CalcKcal()
# Show normalized stacked barchart per participant
NormalizedPercentKcal()
# Plot %kcal of protein, fat, and carbs.
# need to rename the data so that they will be recognized by the functions..
totals <- n450_a
totals$UserName <- totals$SEQN
totals$KCAL <- totals$DR1IKCAL
colnames(totals)
totals$PROT <- totals$DR1IPROT
totals$TFAT <- totals$DR1ITFAT
totals$CARB <- totals$DR1ICARB
totals$SUGR <- totals$DR1ISUGR
# Calculate the mean kcal from carb/protein/fat per participant
CalcKcal()
# Show normalized stacked barchart per participant
NormalizedPercentKcal()
# show a stacked barchart per participant with standard deviations as error bars.
NonNormalizedPercentKcal()
NonNormalizedPercentKcal(show.sd = TRUE)
NonNormalizedPercentKcal(show.sd = TRUE)
# show a stacked barchart per participant without error bars.
NonNormalizedPercentKcal(show.sd = FALSE)
# For most cases, CARB > SUGR, so it's possible that CARB includes SUGR (should be...)
# but not quite sure.
head(totals, 10)
totals$PROT
View(TFATmeans)
totals$UserName
table(totals$UserName)
totals[, c("UserName", "TFAT", "PROT")]
head(totals, 10)
mean.c
str(totals)
# Replace NaN with zero.
totals[ is.na(totals)] <- 0
head(totals)
head(totals, 10)
totals[ is.finite(totals)] <- 0
is(totals)
totals[ which(is.finite(totals))] <- 0
totals[ totals == Inf ] <- 0
totals[ totals == -Inf ] <- 0
head(totals)
head(totals, 10)
# Calculate the mean kcal from carb/protein/fat per participant
CalcKcal()
# Show normalized stacked barchart per participant
NormalizedPercentKcal()
View(mean.p)
View(mean.t)
View(sd.c)
View(mean.t)
View(mean.p)
# ---------------------------------------------------------------------------------------------------------------
# Define your input file. Need to scale it to accommodate measurements in different units.
colnames(selected_variables)
kmeans_input <- scale(selected_variables) # correlated variables removed.
theme_set(theme_bw(base_size = 14))
# ---------------------------------------------------------------------------------------------------------------
# Use the elbow method to find the ideal K.
ElbowMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K.  Uses cluster package.
SilhouetteMethod(k.values = 2:15)
# or use the factoextra package to use the Silhouette method.
factoextra::fviz_nbclust(kmeans_input, kmeans, method="silhouette")
# or use the factoextra package to use the Silhouette method.
factoextra::fviz_nbclust(kmeans_input, kmeans, method="silhouette")
GapMethod(k.values = 1:15)
GapMethod(k.values = 1:15)
FactoextraGapMethod(k.values = 1:15)
FactoextraGapMethod(k.values = 1:15)
FactoextraGapMethod(k.values = 1:15)
# ---------------------------------------------------------------------------------------------------------------
# Perform k-means analysis with multiple (2-4) Ks, and plot them in one window.
MultipleK(myKs = c(2, 3, 5, 10))
# ---------------------------------------------------------------------------------------------------------------
# Perform k-means analysis with multiple (2-4) Ks, and plot them in one window.
MultipleK(myKs = c(2, 3, 4, 5))
View(sd.p)
head(totals, 10)
head(nhanes1718,10)
# Gram weight of the food/individual component
n450 %>% filter(SEQN > 93704) %>% nrow()  # 30
# Gram weight of the food/individual component
n450 %>% filter(SEQN == 93704) %>% nrow()  # 437
# Take the first 450 records.
n450 <- head(nhanes1718, 450)
dim(n450)
# How many participants?
length(unique(n450$SEQN))
library(dplyr)
# Gram weight of the food/individual component
n450 %>% filter(SEQN == 93704) %>% nrow()  # 437
n450 %>% filter(DR1IGRMS > 500) %>% nrow()  # 30
n450 %>% filter(SEQN == 93704) %>% head()
n450 %>% filter(SEQN == 93704) %>% summarize(protmean = mean(DR1IPROT))

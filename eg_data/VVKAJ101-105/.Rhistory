PerformPCA <- function(input, pca.data=pca_input, pca.result=scaled_pca, out.dir, out.prefix){
# Create a scree plot.
screep <<- LineScreePlot(pca.data = pca_input, pca.result = scaled_pca)
# Save your plot
ggsave( paste(out.dir, paste(out.prefix, "_scree.pdf"),   sep= .Platform$file.sep),
screep, device="pdf", width=5, height=5, units="in")
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
biplotdots <<- BiplotDots(pca.result = scaled_pca, pca.data = pca_input, alpha = 0.5)
# Save your plot
ggsave( paste(out.dir, paste(out.prefix, "_biplotdots.pdf"), sep= .Platform$file.sep),
biplotdots, device="pdf", width=5, height=5, units="in")
# Create a biplot with the individuals labeled.
biplotlabeled <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=T)
ggsave( paste(out.dir, paste(out.prefix, "_biplotlabeled.pdf"), sep= .Platform$file.sep),
biplotlabeled, device="pdf", width=5, height=5, units="in")
# Create a biplot with the individuals labeled without the variables' arrows.
biplotlabeledwoarrows <<- BiplotLabeledwoArrows(pca.result=scaled_pca, pca.data=pca_input, individuals.label=T)
ggsave( paste(out.dir, paste(out.prefix, "_biplotlabeledwoarrows.pdf"), sep= .Platform$file.sep),
biplotlabeledwoarrows, device="pdf", width=5, height=5, units="in")
# Plot the directions of the variables.
directions <<- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=F)
ggsave( paste(out.dir, paste(out.prefix, "_directions.pdf"), sep= .Platform$file.sep),
directions, device="pdf", width=5, height=5, units="in")
# Plot the contribution of the variables to a given PC: PC1 here.
loadings_plot_PC1 <<- LoadingsPlot(pca.result=scaled_pca,  whichPC="PC1",
positive.color="green2", negative.color="grey70", sort.variables = T)
ggsave( paste(out.dir, paste(out.prefix, "_loadings_PC1.pdf"), sep= .Platform$file.sep),
loadings_plot_PC1, device="pdf", width=8, height=4.8, units="in")
# Plot the contribution of the variables to a given PC: PC2 here.
loadings_plot_PC2 <<- LoadingsPlot(pca.result=scaled_pca,  whichPC="PC2",
positive.color="green2", negative.color="grey70", sort.variables = T)
ggsave( paste(out.dir, paste(out.prefix, "_loadings_PC2.pdf"), sep= .Platform$file.sep),
loadings_plot_PC2, device="pdf", width=8, height=4.8, units="in")
# ---------------------------------------------------------------------------------------------------------------
# Save the variance explained by each PC as a .txt file.
# Extract the importance of the PCs
pca_summary <- summary(pca.result)
# # Extract the Proportion of Variance
var_explained_values <- pca_summary[["importance"]][2, ]
# Create a dataframe that has the PCs and their importance (var explained by each PC)
var_explained_df <- data.frame(PC = seq(1:length(var_explained_values)),
var_explained = var_explained_values)
write.table(var_explained_df,
paste(out.dir, paste(out.prefix, '_PC_var_explained.txt'), sep= .Platform$file.sep),
sep = "\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Calculate loadings of each PC to the variables and save it as a txt file.
p <- pca.result[["rotation"]]
p <- as.data.frame(scaled_pca[["rotation"]])
# make a variable column.
variables <- rownames(p)
p$Var <- variables
# Sort the columns so that the rownames (variable names) come first
sortedp <- p[, c(length(colnames(p)), 1:length(colnames(p))-1)]
write.table(sortedp,
paste(out.dir, paste(out.prefix, '_PC_loadings.txt'), sep= .Platform$file.sep),
sep = "\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# obtain PC values and save as a txt file
# Define your food input file from which you derived the input for the PCA.
pca_input <- read.table(input, sep="\t", header=T)
# This has food codes and food names.
# extract the PCs
PCs <- as.data.frame(pca.result[["x"]])
# These should have the same number of rows, so their difference should be zero.
diff <- nrow(pca_input) - nrow(PCs)
# Gives an error message if the input and pca.result have a different number of rows.
if(diff != 0){
cat("Error: The input and the PCA results should have the same number of samples.")
}else{
# Add columns
Input_PCs <- cbind(pca_input, PCs)
# Save as a txt file.
write.table(Input_PCs,
paste(out.dir, paste(out.prefix, '_input&PC.txt'), sep= .Platform$file.sep),
sep="\t", row.names = F, quote = F)
}
}
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix,
input= "VVKAJ_2021-11-09_7963_Tot_m_QCed.txt")
# A biplot with the individuals labeled without the variables' arrows.
biplotlabeledwoarrows <- BiplotLabeledwoArrows(pca.result=scaled_pca, pca.data=pca_input,
individuals.label=T)
biplotlabeledwoarrows
biplotlabeledwoarrows + coord_cartesian(xlim=c(-0.1, 0.1), ylim=c(0.05, 0.1))
res_dir = "Nut_asis_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Nut_asis"
# Create a scree plot.
screep <- LineScreePlot(pca.data = pca_input, pca.result = scaled_pca)
screep
ggsave( paste(res_dir, paste(res_prefix, "_scree.pdf"), sep= .Platform$file.sep),
screep, device="pdf", width=5, height=5, units="in")
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
biplotdots <- BiplotDots(pca.result = scaled_pca, pca.data = pca_input, alpha = 0.5)
biplotdots
ggsave( paste(res_dir, paste(res_prefix, "_biplotdots.pdf"), sep= .Platform$file.sep),
biplotdots, device="pdf", width=5, height=5, units="in")
# A biplot with the individuals labeled.
biplotlabeled <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=T)
biplotlabeled
ggsave( paste(res_dir, paste(res_prefix, "_biplotlabeled.pdf"), sep= .Platform$file.sep),
biplotlabeled, device="pdf", width=5, height=5, units="in")
# A biplot with the individuals labeled without the variables' arrows.
biplotlabeledwoarrows <- BiplotLabeledwoArrows(pca.result=scaled_pca, pca.data=pca_input,
individuals.label=T)
biplotlabeledwoarrows
# Zoom in to a particular area of interest in the plot
biplotlabeledwoarrows + coord_cartesian(xlim=c(-0.1, 0.1), ylim=c(0.05, 0.1))
ggsave( paste(res_dir, paste(res_prefix, "_biplotlabeledwoarrows.pdf"), sep= .Platform$file.sep),
biplotlabeledwoarrows, device="pdf", width=5, height=5, units="in")
# Plot the directions of the variables.
directions <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=F)
directions
ggsave( paste(res_dir, paste(res_prefix, "_directions.pdf"), sep= .Platform$file.sep),
directions, device="pdf", width=5, height=5, units="in")
# Plot the contribution of the variables to a given PC: Change the PC and the file name as desired.
LoadingsPlot(pca.result=scaled_pca,  whichPC="PC1",
positive.color="green2", negative.color="grey70", sort.variables = T)
loadings_plot
ggsave( paste(res_dir, paste(res_prefix, "_loadings_PC1.pdf"), sep= .Platform$file.sep),
loadings_plot, device="pdf", width=8, height=4.8, units="in")
ggsave( paste(res_dir, paste(res_prefix, "_loadings_PC1.pdf"), sep= .Platform$file.sep),
loadings_plot, device="pdf", width=8, height=4.8, units="in")
# Specify the directory (folder) to save the results.
res_dir = "Nut_asis_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Nut_asis"
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix,
input= "VVKAJ_2021-11-09_7963_Tot_m_QCed.txt")
# ---------------------------------------------------------------------------------------------------------------
# Nutrient data averaged, processed for clustering analyses.
Tot_m_QCed_Nut_ave <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave.txt", sep="\t", header=T)
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_2021-11-09_7963_Tot_m_QCed.txt", sep = "\t", header = T)
# ---------------------------------------------------------------------------------------------------------------
# 2. If taking average of each user across all days first,
# Specify the data to be used, category to group by, and the range of columns (variables)
# to calculate the means of each variable.
# Nutrients analysis  --> start.col = "PROT",    end.col = "B12_ADD"
AverageBy(data= totals_selected, by= "UserName", start.col= "PROT", end.col= "B12_ADD")
# Results are saved in this dataframe.  Probably too large to see as is.
meansbycategorydf
# The column names should be the same as start.col-end.col.
colnames(meansbycategorydf)
# The row names should be the users to calculate means for.
rownames(meansbycategorydf)
# Pick up only the columns with non-zero variance, in order to run PCA and cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = meansbycategorydf)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
dim( subsetted_non0var)
# 2. If taking average of each user across all days first,
write.table(x=selected_variables, file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave.txt", sep="\t", row.names=F, quote=F)
# 2. If taking average of each user across all days first,
SaveCorrMatrix(x=cc, name = "VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave_corr_matrix.txt")
View(SaveCorrMatrix)
# 2. If taking average of each user across all days first,
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave_corr_matrix.txt")
# ---------------------------------------------------------------------------------------------------------------
# Nutrient data averaged, processed for clustering analyses.
Tot_m_QCed_Nut_ave <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Nut_ave
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix,
input= "VVKAJ_2021-11-09_7963_Tot_m_QCed.txt")
# Results are saved in this dataframe.  Probably too large to see as is.
meansbycategorydf
meansbycategorydf
# Save the averaged results.
write.table(x=meansbycategorydf, "VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave_clus.txt", sep="\t", row.names=F, quote=F)
# The row names should be the users to calculate means for.
rownames(meansbycategorydf)
# The column names should be the same as start.col-end.col.
colnames(meansbycategorydf)
# Pick up only the columns with non-zero variance, in order to run PCA and cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = meansbycategorydf)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# 2. If taking average of each user across all days first,
write.table(x=selected_variables, file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave.txt", sep="\t", row.names=F, quote=F)
# PerformPCA function to create and save PCA plots and outputs all at once.
PerformPCA <- function(pca.data=pca_input, pca.result=scaled_pca, out.dir, out.prefix){
# Create a scree plot.
screep <<- LineScreePlot(pca.data = pca_input, pca.result = scaled_pca)
# Save your plot
ggsave( paste(out.dir, paste(out.prefix, "_scree.pdf"),   sep= .Platform$file.sep),
screep, device="pdf", width=5, height=5, units="in")
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
biplotdots <<- BiplotDots(pca.result = scaled_pca, pca.data = pca_input, alpha = 0.5)
# Save your plot
ggsave( paste(out.dir, paste(out.prefix, "_biplotdots.pdf"), sep= .Platform$file.sep),
biplotdots, device="pdf", width=5, height=5, units="in")
# Create a biplot with the individuals labeled.
biplotlabeled <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=T)
ggsave( paste(out.dir, paste(out.prefix, "_biplotlabeled.pdf"), sep= .Platform$file.sep),
biplotlabeled, device="pdf", width=5, height=5, units="in")
# Create a biplot with the individuals labeled without the variables' arrows.
biplotlabeledwoarrows <<- BiplotLabeledwoArrows(pca.result=scaled_pca, pca.data=pca_input, individuals.label=T)
ggsave( paste(out.dir, paste(out.prefix, "_biplotlabeledwoarrows.pdf"), sep= .Platform$file.sep),
biplotlabeledwoarrows, device="pdf", width=5, height=5, units="in")
# Plot the directions of the variables.
directions <<- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=F)
ggsave( paste(out.dir, paste(out.prefix, "_directions.pdf"), sep= .Platform$file.sep),
directions, device="pdf", width=5, height=5, units="in")
# Plot the contribution of the variables to a given PC: PC1 here.
loadings_plot_PC1 <<- LoadingsPlot(pca.result=scaled_pca,  whichPC="PC1",
positive.color="green2", negative.color="grey70", sort.variables = T)
ggsave( paste(out.dir, paste(out.prefix, "_loadings_PC1.pdf"), sep= .Platform$file.sep),
loadings_plot_PC1, device="pdf", width=8, height=4.8, units="in")
# Plot the contribution of the variables to a given PC: PC2 here.
loadings_plot_PC2 <<- LoadingsPlot(pca.result=scaled_pca,  whichPC="PC2",
positive.color="green2", negative.color="grey70", sort.variables = T)
ggsave( paste(out.dir, paste(out.prefix, "_loadings_PC2.pdf"), sep= .Platform$file.sep),
loadings_plot_PC2, device="pdf", width=8, height=4.8, units="in")
# ---------------------------------------------------------------------------------------------------------------
# Save the variance explained by each PC as a .txt file.
# Extract the importance of the PCs
pca_summary <- summary(pca.result)
# # Extract the Proportion of Variance
var_explained_values <- pca_summary[["importance"]][2, ]
# Create a dataframe that has the PCs and their importance (var explained by each PC)
var_explained_df <- data.frame(PC = seq(1:length(var_explained_values)),
var_explained = var_explained_values)
write.table(var_explained_df,
paste(out.dir, paste(out.prefix, '_PC_var_explained.txt'), sep= .Platform$file.sep),
sep = "\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Calculate loadings of each PC to the variables and save it as a txt file.
p <- pca.result[["rotation"]]
p <- as.data.frame(scaled_pca[["rotation"]])
# make a variable column.
variables <- rownames(p)
p$Var <- variables
# Sort the columns so that the rownames (variable names) come first
sortedp <- p[, c(length(colnames(p)), 1:length(colnames(p))-1)]
write.table(sortedp,
paste(out.dir, paste(out.prefix, '_PC_loadings.txt'), sep= .Platform$file.sep),
sep = "\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# # Probably better to run this function separately because it may be confusing as it uses the totals or averaged
#    # data as 'input', not the one processed for clustering (because the processed ones do not have all the variables;
#    # some variables are filtered out.)
#
#    # Obtain PC values and save as a txt file together with input file (before processing for clustering.)
#
#      # Define your food input file from which you derived the input for the PCA.
#      pca_input <- read.table(input, sep="\t", header=T)
#      # This has food codes and food names.
#
#      # extract the PCs
#      PCs <- as.data.frame(pca.result[["x"]])
#
#      # These should have the same number of rows, so their difference should be zero.
#      diff <- nrow(pca_input) - nrow(PCs)
#
#      # Gives an error message if the input and pca.result have a different number of rows.
#      if(diff != 0){
#
#        cat("Error: The input and the PCA results should have the same number of samples.")
#
#      }else{
#
#      # Add columns
#      Input_PCs <- cbind(pca_input, PCs)
#
#      # Save as a txt file.
#      write.table(Input_PCs,
#                  paste(out.dir, paste(out.prefix, '_input&PC.txt'), sep= .Platform$file.sep),
#                  sep="\t", row.names = F, quote = F)
#      }
}
# Combine the input with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_2021-11-09_7963_Tot_m_QCed.txt", pca.results = scaled_pca,
out.fn = "VVKAJ_2021-11-09_7963_Tot_m_QCed_PCs.txt")
# Nutrient data as is, processed for clustering analyses.
Tot_m_QCed_Nut_asis <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_asis.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Nut_asis
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Specify the directory (folder) to save the results.
res_dir = "Nut_asis_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Nut_asis"
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix )
# ---------------------------------------------------------------------------------------------------------------
# Function to obtain PC values and save as a txt file
SaveInputAndPCs <- function(input, pca.results, out.dir, out.prefix){
# Define your food input file from which you derived the input for the PCA.
pca_input <- read.table(input, sep="\t", header=T)
# This has food codes and food names.
# extract the PCs
PCs <- as.data.frame(pca.results[["x"]])
# These should have the same number of rows, so their difference should be zero.
diff <- nrow(pca_input) - nrow(PCs)
# Gives an error message if the input and pca.result have a different number of rows.
if(diff != 0){
cat("Error: The input and the PCA results should have the same number of samples.")
}else{
# Add columns
Input_PCs <<-  cbind(pca_input, PCs)
# Save as a txt file.
write.table(Input_PCs,
paste(out.dir, paste(out.prefix, '_PCs.txt'), sep= .Platform$file.sep),
sep="\t", row.names = F, quote = F)
}
}
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_2021-11-09_7963_Tot_m_QCed.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)
# ---------------------------------------------------------------------------------------------------------------
# Nutrient data averaged and processed for clustering analyses.
Tot_m_QCed_Nut_ave <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Nut_ave
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Specify the directory (folder) to save the results.
res_dir = "Nut_ave_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Nut_ave"
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
# Input is your items/totals input file before any prep for clustering, from which you derived the input for the PCA.
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix)
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_2021-11-09_7963_Tot_m_QCed.txt", sep = "\t", header = T)
# Define your input dataset (may not be necessary, but keeping this because I'm not
# sure how totals_selected are made. I think it's the same as totals_QC, though.)
totals_selected <- totals
# Food items analysis --> start.col = "F_TOTAL", end.col = "A_DRINKS", 37 varialbes in total.
SubsetColumns(data = totals_selected, start.col = "F_TOTAL", end.col = "A_DRINKS")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# 2. If taking average of each user across all days first,
write.table(x=selected_variables, file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave.txt", sep="\t", row.names=F, quote=F)
# 2. If taking average of each user across all days first,
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_2021-11-09_7963_Tot_m_QCed_Nut_ave_corr_matrix.txt")
# ---------------------------------------------------------------------------------------------------------------
# Food Category data as is, processed for clustering analyses.
Tot_m_QCed_Cat_asis <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_asis.txt", sep="\t", header=T)
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_2021-11-09_7963_Tot_m_QCed.txt", sep = "\t", header = T)
# Define your input dataset (may not be necessary, but keeping this because I'm not
# sure how totals_selected are made. I think it's the same as totals_QC, though.)
totals_selected <- totals
# Food items analysis --> start.col = "F_TOTAL", end.col = "A_DRINKS", 37 varialbes in total.
SubsetColumns(data = totals_selected, start.col = "F_TOTAL", end.col = "A_DRINKS")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
write.table(x=selected_variables, file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_asis.txt", sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Food Category data as is, processed for clustering analyses.
Tot_m_QCed_Cat_asis <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_asis.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Cat_asis
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Specify the directory (folder) to save the results.
res_dir = "Cat_asis_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Cat_asis"
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix )
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_2021-11-09_7963_Tot_m_QCed.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)
# ---------------------------------------------------------------------------------------------------------------
# Food category data averaged and processed for clustering analyses.
Tot_m_QCed_Cat_ave <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave.txt", sep="\t", header=T)
# Food items analysis --> start.col = "F_TOTAL", end.col = "A_DRINKS"
AverageBy(data= totals_selected, by= "UserName", start.col= "F_TOTAL", end.col= "A_DRINKS")
write.table(x=meansbycategorydf, "VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave_clus.txt", sep="\t", row.names=F, quote=F)
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="09_7963_Tot_m_QCed_Nut_ave_clus.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave_clus.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)
# ---------------------------------------------------------------------------------------------------------------
# Food Category data as is, processed for clustering analyses.
Tot_m_QCed_Cat_asis <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_asis.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Cat_asis
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Specify the directory (folder) to save the results.
res_dir = "Cat_asis_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Cat_asis"
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix )
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_2021-11-09_7963_Tot_m_QCed.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)
# ---------------------------------------------------------------------------------------------------------------
# Food category data averaged and processed for clustering analyses.
Tot_m_QCed_Cat_ave <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave.txt", sep="\t", header=T)
# Food items analysis --> start.col = "F_TOTAL", end.col = "A_DRINKS"
AverageBy(data= totals_selected, by= "UserName", start.col= "F_TOTAL", end.col= "A_DRINKS")
write.table(x=meansbycategorydf, "VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave_clus.txt", sep="\t", row.names=F, quote=F)
# The column names should be the same as start.col-end.col.
colnames(meansbycategorydf)
# The row names should be the users to calculate means for.
rownames(meansbycategorydf)
# Pick up only the columns with non-zero variance, in order to run PCA and cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = meansbycategorydf)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
write.table(x=selected_variables, file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave.txt", sep="\t", row.names=F, quote=F)
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave_corr_matrix.txt")
# ---------------------------------------------------------------------------------------------------------------
# Food category data averaged and processed for clustering analyses.
Tot_m_QCed_Cat_ave <- read.table(file="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Cat_ave
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Specify the directory (folder) to save the results.
res_dir = "Cat_ave_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Cat_ave"
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
# Input is your items/totals input file before any prep for clustering, from which you derived the input for the PCA.
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix)
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_2021-11-09_7963_Tot_m_QCed_Cat_ave_clus.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)

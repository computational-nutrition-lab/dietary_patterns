# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
dim(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the variables after removing correlated variables
write.table(selected_variables,
"fems50s_QCtotal_d_glu_body_meta_demo_Cat_rv.txt",
sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation.
SaveCorrMatrix(x=cc,
out.fn = "fems50s_QCtotal_d_glu_body_meta_demo_Cat_corr_mat.txt")
# ---------------------------------------------------------------------------------------------------------------
# Come back to the main directory
setwd(main_wd)
setwd("~/GitHub/dietarry_patterns")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# Load necessary packages and source scripts
library(ggplot2)
library(ggfortify)
source("lib/specify_data_dir.R")
source("lib/ggplot2themes.R")
source("lib/PCA.R")
# You can come back to the main directory by:
setwd(main_wd)
# Specify where the data is.
SpecifyDataDirectory("eg_data/NHANES/Laboratory_data")
# Your input data should be a data frame with variables with non-zero variance.
pca_input <- read.table("fems50s_QCtotal_d_glu_body_meta_demo_Nut_rv.txt",
sep="\t", header=T)
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
head(pca_input, 2)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x= pca_input, scale= TRUE)
# Specify the directory (folder) to save the results.
res_dir_Nut = "fems50s_Nut_PCA"
# Specify the prefix of filenames to be saved.
res_prefix_Nut = "fems50s_Nut"
# Save PCA output files in a specified folder (out.dir) and a prefix (out.prefix).
OutputPCA(pca.data= pca_input, pca.result= scaled_pca,
out.dir= res_dir_Nut, out.prefix= res_prefix_Nut)
# Specify the directory (folder) to save the results.
res_dir_Nut = "fems50s_Nut_PCA"
# Specify the prefix of filenames to be saved.
res_prefix_Nut = "fems50s_Nut"
# Save PCA output files in a specified folder (out.dir) and a prefix (out.prefix).
OutputPCA(pca.data= pca_input, pca.result= scaled_pca,
out.dir= res_dir_Nut, out.prefix= res_prefix_Nut)
# Combine the input (totals before processing) with all the variables and the PC results.
# Input is your items/totals input file before any prep for clustering, from which you derived the input for the PCA.
SaveInputAndPCs(input="QCtotal_d_glu_body_meta_demo_fems50s.txt", pca.results = scaled_pca,
out.dir= res_dir_Nut, out.prefix= res_prefix_Nut)
# Load the input & PC info.
Nut_PCs <- read.table("fems50s_Nut_PCA/fems50s_Nut_PCs.txt", sep="\t", header=T)
# Change GLU_index to a factor so that factors will be displayed in order.
Nut_PCs$GLU_index <- factor(Nut_PCs$GLU_index, levels= c("Normal", "Prediabetic", "Diabetic"))
# Ellipses.
ell <- ggplot(data= Nut_PCs, aes(x=PC1, y=PC2, color= GLU_index)) +
geom_point(aes(color=GLU_index), size=3 ) +
theme_bw(base_size = 12) + no_grid + theme(aspect.ratio = 1) +
scale_color_manual( values= c("steelblue3", "gold3", "hotpink")) +
stat_ellipse(level=0.95)
ell
# Save as a .pdf.
ggsave("fems50s_Nut_PCA/fems50s_Nut_PCA_by_GLU_index_PC12_ell.pdf", ell,
device="pdf", width=7, height=6.5)
# ---------------------------------------------------------------------------------------------------------------
# Load the glu_3_fems50s data. (The original data before filtering variables)
glu_3_fems50s <- read.table("QCtotal_d_glu_body_meta_demo_fems50s.txt",
sep="\t", header=T)
colnames(glu_3_fems50s)
# Change GLU_index to a factor so that factors will be displayed in order.
glu_3_fems50s$GLU_index <- factor(glu_3_fems50s$GLU_index,
levels= c("Normal", "Prediabetic", "Diabetic"))
# Use the autoplot function. Specify which PC in the x and y arguments.
food_Nut_PCA <- autoplot(scaled_pca, x=1, y=2,
loadings=T, loadings.label=T, loadings.colour = 'grey50',  # loadings.label=T if want to see it
data = glu_3_fems50s,  size= 3 ) +   # data is the original input, not after selecting specific variables.
geom_point(size = 3, alpha = 1, na.rm = T, shape = 21,  aes(fill= GLU_index)) +
theme_bw(base_size = 12) + theme(aspect.ratio = 1) +
theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
scale_fill_manual( values= c("steelblue3", "yellow", "hotpink"))
food_Nut_PCA
ggsave("fems50s_Nut_PCA/fems50s_Nut_PCA_by_GLU_index_PC12.pdf", food_Nut_PCA,
device="pdf", width=7, height=6.5)
# Specify where the data is.
SpecifyDataDirectory("eg_data/NHANES/Laboratory_data")
# Your input data should be a data frame with variables with non-zero variance.
pca_input <- read.table("fems50s_QCtotal_d_glu_body_meta_demo_Cat_rv.txt",
sep="\t", header=T)
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
setwd("~/GitHub/dietarry_patterns")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# Load the necessary functions
source("lib/specify_data_dir.R")
source("lib/prep_data_for_clustering.R")
# You can come back to the main directory by:
setwd(main_wd)
# Specify where the data is.
SpecifyDataDirectory("eg_data/NHANES/Laboratory_data/")
# Load the glu_3_fems50s data.
glu_3_fems50s <- read.table("QCtotal_d_glu_body_meta_demo_fems50s.txt",
sep="\t", header=T)
# There should be 128 individuals (rows)
dim(glu_3_fems50s)
# Are BMI and body weight correlated? - Yes.
plot(glu_3_fems50s$BMXBMI, glu_3_fems50s$BMXWT)
cor.test(glu_3_fems50s$BMXBMI, glu_3_fems50s$BMXWT)
# Define which columns to drop.
drops <- c("KCAL","GRMS", "MOIS", "NoOfItems")
# Take only the columns whose names are NOT in the drop vector.
glu_3_fems50s_2 <- glu_3_fems50s[ , !(names(glu_3_fems50s) %in% drops)]
# ===============================================================================================================
# Scenario B: PCA with food category and body weight
# ===============================================================================================================
# Add BMI or (weight) to the PCA input.
# Food categories.
# The columns specified as start.col, end.col, and all columns in between will be selected.
# Take  start.col="F_CITMLB" through end.col="A_DRINKS" plus, "BMXBMI" and "BMXWT".
# The output is a df called "subsetted".
BMI_col   <- match("BMXBMI"  , names(glu_3_fems50s_2))
WT_col    <- match("BMXWT"   , names(glu_3_fems50s_2))
start_col <- match("F_CITMLB", names(glu_3_fems50s_2))
end_col   <- match("A_DRINKS", names(glu_3_fems50s_2))
# Pick up BMI, weight, and food category variables.
subsetted <- glu_3_fems50s_2[ , c(BMI_col, WT_col, start_col:end_col)]
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
dim(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variable if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x= pca_input, scale= TRUE)
# Specify the directory (folder) to save the results.
res_dir_Cat = "fems50s_Cat_PCA"
# Specify the prefix of filenames to be saved.
res_prefix_Cat = "fems50s_Cat"
# Specify the directory (folder) to save the results.
res_dir_Cat = "fems50s_Cat_PCA"
# Specify the prefix of filenames to be saved.
res_prefix_Cat = "fems50s_Cat"
# Save PCA output files in a specified folder (out.dir) and a prefix (out.prefix).
OutputPCA(pca.data=pca_input, pca.result=scaled_pca,
out.dir= res_dir_Cat, out.prefix= res_prefix_Cat)
# Combine the input (totals before processing) with all the variables and the PC results.
# Input is your items/totals input file before any prep for clustering, from which you derived the input for the PCA.
SaveInputAndPCs(input="QCtotal_d_glu_body_meta_demo_fems50s.txt", pca.results = scaled_pca,
out.dir= res_dir_Cat, out.prefix= res_prefix_Cat)
# Combine the input (totals before processing) with all the variables and the PC results.
# Input is your items/totals input file before any prep for clustering, from which you derived the input for the PCA.
SaveInputAndPCs(input="QCtotal_d_glu_body_meta_demo_fems50s.txt", pca.results = scaled_pca,
out.dir= res_dir_Cat, out.prefix= res_prefix_Cat)
# Load the input & PC info.
Cat_PCs <- read.table("fems50s_Cat_PCA/fems50s_Cat_PCs.txt", sep="\t", header=T)
# Change GLU_index to a factor so that the levels will be displayed in order.
Cat_PCs$GLU_index <- factor(Cat_PCs$GLU_index, levels= c("Normal", "Prediabetic", "Diabetic"))
# Ellipses. Specify which PCs to plot. Specify which PC in the x and y arguments.
ell <- ggplot(data= Cat_PCs, aes(x=PC1, y=PC2, color= GLU_index)) +
geom_point(aes(color=GLU_index), size=3 ) +
theme_bw(base_size = 12) + no_grid + space_axes + theme(aspect.ratio = 1) +
scale_color_manual( values= c("steelblue3", "gold3", "hotpink")) +
stat_ellipse(level=0.95)
ell
# Save as a .pdf.
ggsave("fems50s_Cat_PCA/fems50s_Cat_PCA_by_GLU_index_PC12_ell.pdf", ell,
device="pdf", width=7, height=6.5)
# ---------------------------------------------------------------------------------------------------------------
# Load the glu_3_fems50s data.
glu_3_fems50s <- read.table("QCtotal_d_glu_body_meta_demo_fems50s.txt",
sep="\t", header=T)
# Change GLU_index to a factor so that factors will be displayed in order.
glu_3_fems50s$GLU_index <- factor(glu_3_fems50s$GLU_index,
levels= c("Normal", "Prediabetic", "Diabetic"))
# Use the autoplot function. Specify which PC in the x and y arguments.
food_Cat_PCA <- autoplot(scaled_pca, x=1, y=2,
loadings=T, loadings.label=T, loadings.colour = 'grey50',  # loadings.label=T if want to see it
data = glu_3_fems50s,  size= 3 ) +            # The original data before filtering.
geom_point(size = 3, alpha = 1, na.rm = T, shape = 21,  aes(fill= GLU_index)) +
theme_bw(base_size = 12) + theme(aspect.ratio = 1) +
theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
scale_fill_manual( values= c("steelblue3", "yellow", "hotpink"))
food_Cat_PCA
ggsave("fems50s_Cat_PCA/fems50s_Cat_PCA_by_GLU_index_PC12.pdf", food_Cat_PCA,
device="pdf", width=7, height=6.5)
# ---------------------------------------------------------------------------------------------------------------
# Come back to the main directory.
setwd(main_wd)
setwd("~/GitHub/dietarry_patterns")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# ---------------------------------------------------------------------------------------------------------------
# Load source scripts
source("lib/specify_data_dir.R")
source("lib/Food_tree_scripts/newick.tree.r")
source("lib/Food_tree_scripts/check.db.r")
source("lib/Food_tree_scripts/format.foods.r")
source("lib/Food_tree_scripts/filter.db.by.diet.records.r")
source("lib/Food_tree_scripts/make.food.tree.r")
source("lib/Food_tree_scripts/make.food.otu.r")
source("lib/Food_tree_scripts/make.fiber.otu.r")
source("lib/Food_tree_scripts/make.dhydrt.otu.r")
# You can come back to the main directory by:
setwd(main_wd)
# Specify where the data is.
SpecifyDataDirectory("eg_data/NHANES/Laboratory_data")
# Load the fems50s people. Note this is a total data (1 row/person).
glu_3_fems50s <- read.table("QCtotal_d_glu_body_meta_demo_fems50s.txt",
sep="\t", header=T)
# Make the individuals as a vector.
selectedind <- glu_3_fems50s$SEQN
# Load the input file (all food record data) to be filtered.
all.food.record <- read.table("../Food_D12_FC_cc_f.txt", sep="\t", header=T)
# Select only the individuals listed in 'selectedind'.
sel.food.record <- all.food.record[all.food.record$SEQN %in% selectedind, ]
# Confirm the two contains the same set of individuals.
identical(unique(sel.food.record$SEQN), selectedind)
# Save. This will be the input in the following procedures.
write.table(sel.food.record, "Food_D12_FC_cc_f_fems50s.txt",
sep="\t", row.names=F, quote=F)
# ===============================================================================================================
# Limit to just the foods reported in your study (formatted dietrecords.txt as the input)
# ===============================================================================================================
# Keep only the foods reported in your study. This is already done, but need to run this
# so that the data will be formatted in a compatible way to create food tree.
FilterDbByDietRecords(food_database_fn = "../../NHANES1516/processed/NHANESDatabase.txt",
food_records_fn  = "Food_D12_FC_cc_f_fems50s.txt",   # output of FormatFoods.
output_fn =        "Food_D12_FC_cc_f_fems50s_red.txt")
# ===============================================================================================================
# Limit to just the foods reported in your study (formatted dietrecords.txt as the input)
# ===============================================================================================================
# Keep only the foods reported in your study. This is already done, but need to run this
# so that the data will be formatted in a compatible way to create food tree.
FilterDbByDietRecords(food_database_fn = "../../Food_tree_eg/NHANESDatabase.txt",
food_records_fn  = "Food_D12_FC_cc_f_fems50s.txt",   # output of FormatFoods.
output_fn =        "Food_D12_FC_cc_f_fems50s_red.txt")
# Check if there is any food item reported by people but are missing in the database.
check.db(food_database_fn = "../../Food_tree_eg/NHANESDatabase.txt",
food_records_fn =  "Food_D12_FC_cc_f_fems50s_red.txt",
output_fn =        "Food_D12_FC_cc_f_fems50s_red_missing.txt")
# Load the output and check if the output contains anything?
mmm = read.table("Food_D12_FC_cc_f_fems50s_red_missing.txt", sep="\t", header=T)
head(mmm)
# Create food tree with the reduced dataset (only reported foods) classified at
# a desired level of classification (Lv. 1-6).
# "NodeLabelsMCT.txt" has a list of food levels and names, which comes with this package.
MakeFoodTree(nodes_fn="../../Food_tree_eg/NodeLabelsMCT.txt",
addl_foods_fn = NULL,
num.levels = 4,
food_database_fn =   "Food_D12_FC_cc_f_fems50s_red.txt",
output_tree_fn =     "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.nwk",
output_taxonomy_fn = "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.taxonomy.txt"
)
# Make the standard food otu table with data in gram weights of food.
MakeFoodOtu(food_records_fn=  "Food_D12_FC_cc_f_fems50s.txt",  # need to supply data that have 'FoodAmt' before applying FilterDBByDietRecords.
food_record_id =  "SEQN",                          # The ID of your participants
food_taxonomy_fn= "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.taxonomy.txt",  # Your taxonomy file produced by MakeFoodTree.
output_fn =       "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.food.otu.txt")  # Output otu file to be saved.
# Make a food otu table with data in grams of fiber per food
MakeFiberOtu(food_records_fn=  "Food_D12_FC_cc_f_fems50s.txt",
food_record_id=   "SEQN",
food_taxonomy_fn= "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.taxonomy.txt",
output_fn=        "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.fiber.otu.txt")
# Make a food otu table as dehydrated grams per kcal
MakeDhydrtOtu(food_records_fn=  "Food_D12_FC_cc_f_fems50s.txt",
food_record_id =  "SEQN",
food_taxonomy_fn= "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.taxonomy.txt",
output_fn =       "Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.dhydrt.otu.txt")
# Come back to the main directory.
setwd(main_wd)
setwd("~/GitHub/dietarry_patterns")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# ---------------------------------------------------------------------------------------------------------------
# Install BiocManager in order to install the "phyloseq" package.
if (!require("BiocManager", quietly = TRUE))install.packages("BiocManager")
# load the necessary packages and source code.
library(phyloseq)
library(ggplot2)
library(ggtree)
library(SASxport)
source("lib/unifrac_ordination.R")
source("lib/specify_data_dir.R")
source("lib/ggplot2themes.R")
# Load the distinct 100 colors for use.
distinct100colors <- readRDS("~/GitHub/R_Toolbox/distinct100colors.rda")
# You can come back to the main directory by:
setwd(main_wd)
# Set working directory.
SpecifyDataDirectory("eg_data/NHANES/Laboratory_data/")
# Food
# Load food OTU table - this is our food OTU data
food <- read.delim("Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.dhydrt.otu.txt", row.names=1)
# Format the food file and create a otu_table called OTU.
PrepFood(data=food)
source("lib/unifrac_ordination.R")
# source("lib/unifrac_ordination.R")
source("lib/ordination.R")
setwd("~/GitHub/dietarry_patterns")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# load the necessary packages and source code.
library(phyloseq)
library(ggplot2)
library(ggtree)
library(SASxport)
# source("lib/unifrac_ordination.R")
source("lib/ordination.R")
source("lib/specify_data_dir.R")
source("lib/ggplot2themes.R")
# Load the distinct 100 colors for use.
distinct100colors <- readRDS("~/GitHub/R_Toolbox/distinct100colors.rda")
# You can come back to the main directory by:
setwd(main_wd)
# Set working directory.
SpecifyDataDirectory("eg_data/NHANES/Laboratory_data/")
# Food
# Load food OTU table - this is our food OTU data
food <- read.delim("Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.dhydrt.otu.txt", row.names=1)
# Format the food file and create a otu_table called OTU.
PrepFood(data=food)
# Take a look at the food file.
# The column name of "food" is SEQN preceded with an 'X'.
food[1:8, 1:8]
# Taxonomy (tax)
# Load taxonomy file generated by the MakeFoodTree function.
tax <- read.delim("Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.taxonomy.txt")
# Format the tax file and create a taxonomy table called TAX.
PrepTax(data=tax)
# Sample
# Load the demographics data.
demog <- read.xport("../Raw_data/DEMO_I.XPT")
# Load a dataset that has the "GLU_index" information.
glu <- read.delim( file="QCtotal_d_glu_body_meta.txt", sep= "\t", header= T )
# Take out only the SEQN and GLU_index.
SEQN_GLU <- glu[, c("SEQN", "GLU_index")]
# Add GLU_index to metadata.
demog_glu <- merge(x=SEQN_GLU, y=demog, all.x=TRUE, by="SEQN")
# Now, it has GLU_index.
head(demog_glu, 2)
# Put 'X' in front of the SEQN and define it as rownames.
rownames(demog_glu) <- paste("X", demog_glu$SEQN, sep="")
# Prep metadata for generating a phyloseq object.
PrepMeta_NHANES(data= demog_glu)
# Food tree
# Load foodtree file generated by the MakeFoodTree function.
foodtree <- read_tree("Foodtree/Food_D12_FC_cc_f_fems50s_red_Lv4.nwk")
# Format the food tree and save it as 'TREE'.
PrepTree(data=foodtree)
# ---------------------------------------------------------------------------------------------------------------
# Make a phyloseq object with OTU, TAX, samples, and foodtree by using the phyloseq function.
phyfoods <- phyloseq(OTU, TAX, SAMPLES, TREE)
# Check your metadata
# Show the sample names. Change n to adjust the number of rows to show.
head(sample_names(phyfoods), n=6)
# Show metadata.
head(sample_data(phyfoods), n=2)
# Show only the columns (variables) of metadata.
sample_variables(phyfoods)
# Check the level 1 foods in your food tree
L1s <- tax_table(phyfoods)[, "L1"]
as.vector(unique(L1s))
# Change to the folder called "Ordination" in your "Ordination" folder.
SpecifyDataDirectory(directory.name = "eg_data/NHANES/Laboratory_data/Ordination/")
# Perform Principal Coordinate Analysis (PCoA) with WEIGHTED unifrac distance of your food data.
# This may take a few minutes depending on your data size.
# e.g. a large phyloseq object (7.9 MB) could take a few minutes.
ordinated_w <- phyloseq::ordinate(phyfoods, method="PCoA", distance="unifrac", weighted=TRUE)
# Save the percent variance explained by the axes as a vector to use in plots.
eigen_percent_w <- ordinated_w$values$Relative_eig
# Save the percent variance explained as a txt file.
Eigen(eigen.input = eigen_percent_w,
output.fn="Food_D12_FC_cc_f_fems50s_red_Lv4_ord_WEIGHTED_eigen.txt")
# Merge the first n axes to the metadata and save it as a txt file.
# The merged dataframe, 'meta_usersdf', will be used for plotting.
MergeAxesAndMetadata_NHANES(ord.object= ordinated_w, number.of.axes= 10, meta.data= demog_glu,
output.fn= "Food_D12_FC_cc_f_fems50s_red_Lv4_ord_WEIGHTED_meta_users.txt")
# Load the output again for plotting.
loaded_glu_w <- read.table("Food_D12_FC_cc_f_fems50s_red_Lv4_ord_WEIGHTED_meta_users.txt",
sep="\t", header=T)
# Convert the GLU_index as a factor to plot it in order.
loaded_glu_w$GLU_index <- factor(loaded_glu_w$GLU_index, labels= c("Normal", "Prediabetic", "Diabetic"))
# ---------------------------------------------------------------------------------------------------------------
# Plot Axis 1 and Axis 2 to show the separation of samples colored by Groups as in the metadata.
p1_w <- ggplot(loaded_glu_w, aes(x=Axis.1, y=Axis.2, color=GLU_index)) +
geom_point(aes(color= GLU_index), size=3) +
scale_color_manual( values= c("turquoise2", "goldenrod3", "mediumvioletred")) +
xlab( paste("Axis.1 (", paste(round(eigen_percent_w[1]*100, 1)), "%)", sep="") ) +
ylab( paste("Axis.2 (", paste(round(eigen_percent_w[2]*100, 1)), "%)", sep="") ) +
no_grid + space_axes + theme(aspect.ratio = 1)
p1_w
# Save p1 as a PDF.
ggsave("Food_D12_FC_cc_f_fems50s_red_Lv4_ord_WEIGHTED_Axis12_p1.pdf",
p1_w, device="pdf", width=7, height=5.5, unit="in", dpi=300)
# You can add ellipses at a desired confidence level; but with this
# example data, there are too few samples per user to draw them.
ellipses_w <- p1_w + stat_ellipse(level=0.95)
ellipses_w
# Save ellipses as a PDF.
ggsave("Food_D12_FC_cc_f_fems50s_red_Lv4_ord_WEIGHTED_Axis12_ellipses.pdf",
ellipses_w, device="pdf", width=7, height=5.5, unit="in", dpi=300)
# Generate a weighted unifrac distance matrix.
dist_matrix_w <- phyloseq::distance(phyfoods, method = "wunifrac") # weighted
# Dispersion test and plot
# vegan::betadisper computes centeroids and distance of each datapoint from it.
dispr_w <- vegan::betadisper(d=dist_matrix_w, phyloseq::sample_data(phyfoods)$GLU_index)
# Can show the centroids and dispersion of each group.
plot(dispr_w)
# Or show the distance to centroid of each datapoint.
boxplot(dispr_w, xlab = "")
# Use dispr to do a permutation test for homogeneity of multivariate dispersion
vegan::permutest(dispr_w)
# Use dispr to do a permutation test for homogeneity of multivariate dispersion
vegan::permutest(dispr_w)
# Use dispr to do a permutation test for homogeneity of multivariate dispersion
vegan::permutest(dispr_w)
# Use adonis to test whether there is a difference between groups' composition.
# i.e., composition among groups (food they consumed) is similar or not.
vegan::adonis(dist_matrix_w ~ phyloseq::sample_data(phyfoods)$GLU_index)
# Use adonis to test whether there is a difference between groups' composition.
# i.e., composition among groups (food they consumed) is similar or not.
vegan::adonis(dist_matrix_w ~ phyloseq::sample_data(phyfoods)$GLU_index)
# Use adonis to test whether there is a difference between groups' composition.
# i.e., composition among groups (food they consumed) is similar or not.
vegan::adonis(dist_matrix_w ~ phyloseq::sample_data(phyfoods)$GLU_index)
# Perform Principal Coordinate Analysis (PCoA) with UNweighted unifrac distance of your food data.
# This may take a few minutes depending on your data size.
# e.g. a large phyloseq object (7.9 MB) takes ~ 1 min.
ordinated_u <- phyloseq::ordinate(phyfoods, method="PCoA", distance="unifrac", weighted=FALSE)
# Save the percent variance explained by the axes as a vector to use in plots.
eigen_percent_u <- ordinated_u$values$Relative_eig
# Save the percent variance explained as a txt file.
Eigen(eigen.input = eigen_percent_u,
output.fn="Food_D12_FC_cc_f_fems50s_red_Lv4_ord_UNweighted_eigen.txt")
# Merge the first n axes to the metadata and save it as a txt file.
# The merged dataframe, 'meta_usersdf', will be used for plotting.
MergeAxesAndMetadata_NHANES(ord.object= ordinated_u, number.of.axes= 10, meta.data= demog_glu,
output.fn= "Food_D12_FC_cc_f_fems50s_red_Lv4_ord_UNweighted_meta_users.txt")
# Load the output again for plotting.
loaded_glu_u <- read.table("Food_D12_FC_cc_f_fems50s_red_Lv4_ord_UNweighted_meta_users.txt",
sep="\t", header=T)
# Convert the GLU_index as a factor to plot it in order.
loaded_glu_u$GLU_index <- factor(loaded_glu_u$GLU_index, labels= c("Normal", "Prediabetic", "Diabetic"))
# Take a look at meta_usersdf_loaded.
head(loaded_glu_u, 2)
# ---------------------------------------------------------------------------------------------------------------
# Plot Axis 1 and Axis 2 to show the separation of samples colored by Groups as in the metadata.
p1_u <- ggplot(loaded_glu_u, aes(x=Axis.1, y=Axis.2, color=GLU_index)) +
geom_point(aes(color= GLU_index), size=3) +
scale_color_manual( values= c("turquoise2", "goldenrod3", "mediumvioletred") ) +
xlab( paste("Axis.1 (", paste(round(eigen_percent_u[1]*100, 1)), "%)", sep="") ) +
ylab( paste("Axis.2 (", paste(round(eigen_percent_u[2]*100, 1)), "%)", sep="") ) +
no_grid + space_axes + theme(aspect.ratio = 1)
p1_u
# Save p1 as a PDF.
ggsave("Food_D12_FC_cc_f_fems50s_red_Lv4_ord_UNweighted_Axis12_p1.pdf",
p1_u, device="pdf", width=7, height=5.5, unit="in", dpi=300)
# You can add ellipses at a desired confidence level; but with this
# example data, there are too few samples per user to draw them.
ellipses_u <- p1_u + stat_ellipse(level=0.95)
ellipses_u
# Save ellipses as a PDF.
ggsave("Food_D12_FC_cc_f_fems50s_red_Lv4_ord_UNweighted_Axis12_ellipses.pdf",
ellipses_u, device="pdf", width=7, height=5.5, unit="in", dpi=300)
# Generate an UNweighted unifrac distance matrix.
dist_matrix_u <- phyloseq::distance(phyfoods, method="unifrac")  # UNweighted
# Dispersion test and plot
# vegan::betadisper computes centeroids and distance of each datapoint from it.
dispr_u <- vegan::betadisper(dist_matrix_u, phyloseq::sample_data(phyfoods)$GLU_index)
# Can show the centroids and dispersion of each group.
plot(dispr_u)
# Or show the distance to centroid of each datapoint
boxplot(dispr_u, xlab = "")
# Use dispr to do a permutation test for homogeneity of multivariate dispersion.
vegan::permutest(dispr_u)
# Use dispr to do a permutation test for homogeneity of multivariate dispersion.
vegan::permutest(dispr_u)
# The results will be slightly different because this is a permutation-based test,
# which conducts 999 permutation tests by default.
# p-values are ~0.01, so, significant. That means dispersion of the groups IS different.
# Thus, the assumption of homogeneity of dispersion is not met. Hmm...
# If it is significant, add pairwise=T argument and see which combination(s) are
# significantly different.
vegan::permutest(dispr_u, pairwise=T)
# Use adonis to test whether there is a difference between groups' composition.
# i.e., composition among groups (food they consumed) is similar or not.
vegan::adonis(dist_matrix_u ~ phyloseq::sample_data(phyfoods)$GLU_index)
# Use adonis to test whether there is a difference between groups' composition.
# i.e., composition among groups (food they consumed) is similar or not.
vegan::adonis(dist_matrix_u ~ phyloseq::sample_data(phyfoods)$GLU_index)
# Can show the centroids and dispersion of each group.
plot(dispr_u)

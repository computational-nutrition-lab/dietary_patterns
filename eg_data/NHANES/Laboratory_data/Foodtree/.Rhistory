glu_3_males50s$GLU_index <- factor(glu_3_males50s$GLU_index,
levels = c('Normal', 'Prediabetic', 'Diabetic'))
# Are BMI and body weight correlated? - Yes.
plot(glu_3_males50s$BMXBMI, glu_3_males50s$BMXWT)
cor.test(glu_3_males50s$BMXBMI, glu_3_males50s$BMXWT)
# Define which columns to drop.
drops <- c("KCAL","GRMS", "MOIS", "NoOfItems")
# Take only the columns whose names are NOT in the drop vector.
aaa <- glu_3_males50s[ , !(names(glu_3_males50s) %in% drops)]
aaa(glu_3_males50s)
# Take only the columns whose names are NOT in the drop vector.
aaa <- glu_3_males50s[ , !(names(glu_3_males50s) %in% drops)]
aaa(glu_3_males50s)
head(glu_3_males50s_2)
# Take only the columns whose names are NOT in the drop vector.
glu_3_males50s_2 <- glu_3_males50s[ , !(names(glu_3_males50s) %in% drops)]
head(glu_3_males50s_2)
# ===============================================================================================================
# Scenario A: PCA with nutrients and body weight
# ===============================================================================================================
# Add BMI or (weight) to the PCA input.
# Nutrients
# Take  start.col="PROT" through end.col="P226" plus, "BMXBMI" and "BMXWT".
BMI_col   <- match("BMXBMI" , names(glu_3_males50s_2))
WT_col    <- match("BMXWT"  , names(glu_3_males50s_2))
start_col <- match("PROT"   , names(glu_3_males50s_2))
end_col   <- match("P226"   , names(glu_3_males50s_2))
# Pick up BMI, weight, and nutrient variables.
subsetted <- glu_3_males50s_2[ , c(BMI_col, WT_col, start_col:end_col)]
head(subsetted, 1)
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
dim(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variable if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the variables after removing correlated variables
write.table(selected_variables,
"males50s_QCtotal_d_glu_body_meta_demo_Nut_rv.txt",
sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation.
SaveCorrMatrix(x=cc,
out.fn= "males50s_QCtotal_d_glu_body_meta_demo_Nut_corr_mat.txt")
# ===============================================================================================================
# Scenario B: PCA with food category and body weight
# ===============================================================================================================
# Add BMI or (weight) to the PCA input.
# Food categories.
# The columns specified as start.col, end.col, and all columns in between will be selected.
# Take  start.col="F_CITMLB" through end.col="A_DRINKS" plus, "BMXBMI" and "BMXWT".
# The output is a df called "subsetted".
BMI_col   <- match("BMXBMI" , names(glu_3_males50s_2))
WT_col    <- match("BMXWT" , names(glu_3_males50s_2))
# Pick up BMI, weight, and food category variables.
subsetted <- glu_3_males50s_2[ , c(BMI_col, WT_col, start_col:end_col)]
head(subsetted, 1)
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
dim(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variable if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the variables after removing correlated variables
write.table(selected_variables,
"males50s_QCtotal_d_glu_body_meta_demo_Cat_rv.txt",
sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation.
SaveCorrMatrix(x=cc,
out.fn = "males50s_QCtotal_d_glu_body_meta_demo_Cat_corr_mat.txt")
cor.test(glu_3_males50s$BMXBMI, glu_3_males50s$BMXWT)
# ===============================================================================================================
# Scenario A: PCA with nutrients and body weight
# ===============================================================================================================
# Add BMI (or weight) to the PCA input.
# Nutrients
# Take  start.col="PROT" through end.col="P226" plus, "BMXBMI" and "BMXWT".
BMI_col   <- match("BMXBMI" , names(glu_3_males50s_2))
WT_col    <- match("BMXWT"  , names(glu_3_males50s_2))
start_col <- match("PROT"   , names(glu_3_males50s_2))
end_col   <- match("P226"   , names(glu_3_males50s_2))
# Pick up BMI, weight, and nutrient variables.
subsetted <- glu_3_males50s_2[ , c(BMI_col, WT_col, start_col:end_col)]
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
dim(subsetted_non0var)
dim(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variable if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ===============================================================================================================
# Scenario B: PCA with food category and body weight
# ===============================================================================================================
# Add BMI or (weight) to the PCA input.
# Food categories.
# The columns specified as start.col, end.col, and all columns in between will be selected.
# Take  start.col="F_CITMLB" through end.col="A_DRINKS" plus, "BMXBMI" and "BMXWT".
# The output is a df called "subsetted".
BMI_col   <- match("BMXBMI"  , names(glu_3_males50s_2))
WT_col    <- match("BMXWT"   , names(glu_3_males50s_2))
start_col <- match("F_CITMLB", names(glu_3_males50s_2))
end_col   <- match("A_DRINKS", names(glu_3_males50s_2))
# Pick up BMI, weight, and food category variables.
subsetted <- glu_3_males50s_2[ , c(BMI_col, WT_col, start_col:end_col)]
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# Check the columns (variables) remained.
colnames(subsetted_non0var)
dim(subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variable if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var,
min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check to see the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
dim( selected_variables)
# ---------------------------------------------------------------------------------------------------------------
# Save the variables after removing correlated variables
write.table(selected_variables,
"males50s_QCtotal_d_glu_body_meta_demo_Cat_rv.txt",
sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation.
SaveCorrMatrix(x=cc,
out.fn = "males50s_QCtotal_d_glu_body_meta_demo_Cat_corr_mat.txt")
# Come back to the main directory
setwd(main_wd)
# Import source code to run the analyses to follow.
source("lib/specify_data_dir.R")
source("lib/k-means.R")
# ---------------------------------------------------------------------------------------------------------------
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/NHANES/Laboratory_data/")
# Your input data should be a data frame with variables with non-zero variance.
nut_kmeansinput <- read.table("males50s_QCtotal_d_glu_body_meta_demo_Nut_rv.txt",
sep="\t", header=T)
# Ensure your input file has the correct number of rows and columns.
dim(nut_kmeansinput)
# Your input data should be a data frame with variables with non-zero variance.
cat_kmeansinput <- read.table("males50s_QCtotal_d_glu_body_meta_demo_Cat_rv.txt",
sep="\t", header=T)
# Ensure your input file has the correct number of rows and columns.
dim(cat_kmeansinput)
source("lib/k-means.R")
# Come back to the main directory
setwd(main_wd)
source("lib/k-means.R")
# ---------------------------------------------------------------------------------------------------------------
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/NHANES/Laboratory_data/")
# Your input data should be a data frame with variables with non-zero variance.
nut_kmeansinput <- read.table("males50s_QCtotal_d_glu_body_meta_demo_Nut_rv.txt",
sep="\t", header=T)
# Ensure your input file has the correct number of rows and columns.
dim(nut_kmeansinput)
# Scale your input file and name it as k-means_input.
kmeans_input <- scale(nut_kmeansinput)
# Specify the directory (folder) to save the results. (create a folder named as this if not done so)
res_dir_nut = "males50s_Nut_k-means"
# Specify the prefix of filenames to be saved.
res_prefix_nut = "males50s_Nut"
# Run elbow, silhouette, and gap methods to find an optimum K (number of clusters).
# Do not alter the name of the input file: kmeans_input. This function below assumes that
# the input is named as "kmeans_input".
# You can only run those three methods for K = 1 through (number of observations - 1).
# The gap method output will be printed on the Console. The gap values are plotted in
# xxx_gapmethod.pdf.
ChooseK(out.dir= res_dir_nut, out.prefix= res_prefix_nut)
# FUNCTIONS ==============================================================================
# ========================================================================================
# k-means clustering
# Version 1
# Created on 01.06.2022 by Rie Sadohara
# ========================================================================================
# ========================================================================================
# Find the ideal k
#  Modified code from https://uc-r.github.io/kmeans_clustering
# ========================================================================================
# ---------------------------------------------------------------------------------------------------------------
# Function to do the Elbow method.
ElbowMethod <- function(k.values=1:15){
# set.seed(123)
# Define a function to compute total within-cluster sum of square
wss <- function(k, data) {
kmeans(data, k, nstart = 25)$tot.withinss
}
# extract wss for 2-15 clusters
wsstable <- data.frame(K=k.values, WithinClusterSS=NA)
for(i in k.values){
wssvalue <- wss(k.values[i], data = kmeans_input)
wsstable[i, 2] <- wssvalue
}
# create a wss value plot
ggplot(wsstable, aes(x = K, y = WithinClusterSS)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = 1:nrow(wsstable)) +
labs(x = "Number of clusters K",
y = "Total within-clusters sum of squares") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
}
# ---------------------------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------------
# Find the ideal k: the Silhouette method
SilhouetteMethod <- function(k.values = 2:15){
# need the cluster package
library(cluster)
# Define avg_sil function first.
avg_sil <- function(number){
km.res <- kmeans(kmeans_input, centers=number, nstart=25)
ss <<- silhouette(km.res$cluster, dist(kmeans_input))
mean(ss[, 3])
}
# Create a dataframe with k values.
siltable3  <- data.frame(K=k.values)
# Apply avg_sil function to each of the K and save results as a vector.
resultvec <- apply(siltable3, MARGIN=1, FUN = avg_sil)
# Save the result vector as a new column of siltable.
siltable3$Avg_Silhouette <- resultvec
# Plot K and the Silhouette values.
ggplot(siltable3, aes(x = K, y = Avg_Silhouette)) +
geom_line() +
geom_point() +
scale_x_continuous(breaks = siltable3$K) +
labs(x = "Number of clusters K",
y = "Average Silhouettes") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
# The K with the max average Silhouette value is the ideal K.
}
# ---------------------------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------------
# Find the ideal k: Gap statistic method
GapMethod <- function(k.values=1:15){
# Calculate the gap statistic.
library(cluster)
gap_stat <- clusGap(kmeans_input, FUN = kmeans, nstart = 25,
K.max = k.values[length(k.values)],
B=50) # B is the number of bootstrapping
# Print the result.
print(gap_stat, method = "firstmax")
# Convert the table to a dataframe first.
gap_stat_df <- as.data.frame(gap_stat[1])
# Add the number of clusters as a new column.
gap_stat_df$NumberofK <- k.values
# Plot the gap statistic with ggplot2
require(ggplot2)
ggplot(gap_stat_df, aes(x=NumberofK, y=Tab.gap)) +
geom_line() +
geom_point() +
geom_errorbar(aes(ymin=Tab.gap-Tab.SE.sim,
ymax=Tab.gap+Tab.SE.sim),
width=0.2,
position=position_dodge(0.05)) +
scale_x_continuous(breaks = 1:nrow(gap_stat_df)) +
labs(x = "Number of clusters K",
y = "Gap stastistic") +
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 0.9)
# The highest K is the optimum K.
}
# Or use the factoextra package.
FactoextraGapMethod <- function(k.values = 1:15){
library(cluster)
# Calculate Gap statistics first.
gap_stat <- clusGap(kmeans_input, FUN = kmeans, nstart = 25,
K.max = k.values[length(k.values)],
B=50) # B is the number of bootstrapping
# Print the result.
print(gap_stat, method = "firstmax")
# Visualize. The best K is marked with a dotted line.
factoextra::fviz_gap_stat(gap_stat)
}
# ---------------------------------------------------------------------------------------------------------------
# ========================================================================================
# Run 3 methods to find the best K and save the output in specified folder.
# The 3 methods are: elbow, silhouette, and gap methods.
# ========================================================================================
ChooseK <- function(out.dir= res_dir, out.prefix= res_prefix){
# Set your ggplot2 theme.
require(ggplot2)
theme_set(theme_bw(base_size = 14))
# Set seed for consistent results.
set.seed(123)
# Detemine max K to try. If there are 15 or more observations, go with 15;
# if there are less than 15 observations, go with the number of observations.
if(nrow(kmeans_input)<15){
maxK = nrow(kmeans_input)
}else{
maxK = 15
}
# ---------------------------------------------------------------------------------------------------------------
# Use the elbow method to find the ideal K. K cannot be larger than the number of datapoints (rows) in input.
elbowmethod <- ElbowMethod(k.values = 1 : (maxK-1) )
# Save the elbowmethod graphic (K vs total within-clusters sum of squares) as a PDF.
ggsave( paste(out.dir, paste(out.prefix, "_elbowmethod.png", sep=""), sep= .Platform$file.sep),
elbowmethod, device="png", width=5, height=5, units="in")
# ---------------------------------------------------------------------------------------------------------------
# Use the Silhouette method to find the ideal K. This uses the cluster and factoextra package.
require(factoextra)
silhouettechart <- factoextra::fviz_nbclust(kmeans_input, kmeans, k.max= maxK-1, method="silhouette")
# Save the silhouette method graphic as a PDF.
ggsave( paste(out.dir, paste(out.prefix, "_silhouettemethod.png", sep=""), sep= .Platform$file.sep),
silhouettechart, device="png", width=5, height=5, units="in")
# ---------------------------------------------------------------------------------------------------------------
# Use the factoextra package to use the Gap statistic method.
gapchart <- FactoextraGapMethod(k.values = 1: (maxK-1) )
# Save the silhouette method graphic as a PDF.
ggsave( paste(out.dir, paste(out.prefix, "_gapmethod.png", sep=""), sep= .Platform$file.sep),
gapchart, device="png", width=5, height=5, units="in")
}
# ========================================================================================
# The optimum k should have been identified by now.
#  Do the k-means analysis with your optimum k.
# ========================================================================================
# ---------------------------------------------------------------------------------------------------------------
# Perform k-means analysis with one specified number and plot it.
OneK <- function(myK, out.dir, out.fn){
# k-means analysis
km_results_one <- kmeans(x=kmeans_input, centers = myK, nstart = 25)
# Define your plot title
plot_title_one <- paste("K=", myK, sep = "")
oneKplot <- factoextra::fviz_cluster(km_results_one,
data = kmeans_input,
ellipse = T, ellipse.alpha = 0.1,
show.clust.cent = F,
ggtheme = theme_bw(base_size = 10),
repel = F, labelsize = 10,
main = plot_title_one) + theme(aspect.ratio = 1)
# Save the plot as a PDF file.
ggsave(paste(out.dir, paste(out.fn, ".png", sep=""), sep= .Platform$file.sep),
oneKplot, device="png", width=4, height=4.05, units="in")
}
# ---------------------------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------------
# Loop through multiple Ks
MultipleK <- function(myKs, out.dir, out.fn){
plots <- list()
km_results_mult <- list()
# Perform the k-means analysis, with the optimum number you found above as the 'centers'.
for(i in 1:length(myKs)){
# k-means analysis
km_results_mult[[i]] <- kmeans(x=kmeans_input, centers = myKs[i], nstart = 25)
# Define title for each K
plot_title <- paste("K=", myKs[i], sep = "")
# Plot
plots[[i]] = factoextra::fviz_cluster(km_results_mult[[i]],
data = kmeans_input,
ellipse = T, ellipse.alpha = 0.1,
show.clust.cent = F,
ggtheme = theme_bw(base_size = 10),
repel = F, labelsize = 10,
main = plot_title ) + theme(aspect.ratio = 1)
}
# Install the gridExtra package if needed.
if(!require("gridExtra"))install.packages("gridExtra")
# Arrange the plots in the same panel.
if(length(myKs)==2){
panel <- gridExtra::grid.arrange(plots[[1]], plots[[2]], nrow = round(length(myKs)/2))
}
else if(length(myKs)==3){
panel <- gridExtra::grid.arrange(plots[[1]], plots[[2]], plots[[3]], nrow = round(length(myKs)/2))
}
else if(length(myKs)==4){
panel <- gridExtra::grid.arrange(plots[[1]], plots[[2]], plots[[3]], plots[[4]], nrow = round(length(myKs)/2))
}
else{
return(paste("Only 2-4 plots can be created at one time.", "\n",
"Please enter 2-4 K values and run again."))
}
# Save the plot as a PDF file.
ggsave(paste(out.dir, paste(out.fn, ".png", sep=""), sep= .Platform$file.sep),
panel, device="png", width=8, height=8.1, units="in")
}
# ---------------------------------------------------------------------------------------------------------------
# Run elbow, silhouette, and gap methods to find an optimum K (number of clusters).
# Do not alter the name of the input file: kmeans_input. This function below assumes that
# the input is named as "kmeans_input".
# You can only run those three methods for K = 1 through (number of observations - 1).
# The gap method output will be printed on the Console. The gap values are plotted in
# xxx_gapmethod.pdf.
ChooseK(out.dir= res_dir_nut, out.prefix= res_prefix_nut)
# With specific K values in mind, perform k-means analysis with one specified K.
# Also, change the file name to be saved as a PDF.
OneK(myK= 2, out.dir= res_dir_nut, out.fn = "males50s_Nut_K2")
# Or try multiple Ks and print the biplots in one panel.
# Likewise, change the file name to be saved as a PDF as necessary.
# This uses the factoextra and gridExtra packages.
MultipleK(myKs = c(2,3,4,5), out.dir = res_dir_nut, out.fn = "males50s_Nut_K2-5")
# Your input data should be a data frame with variables with non-zero variance.
cat_kmeansinput <- read.table("males50s_QCtotal_d_glu_body_meta_demo_Cat_rv.txt",
sep="\t", header=T)
# Ensure your input file has the correct number of rows and columns.
dim(cat_kmeansinput)
# Scale your input file and name it as k-means_input.
kmeans_input <- scale(cat_kmeansinput)
# Specify the directory (folder) to save the results.
res_dir_cat = "males50s_Cat_k-means"
# Specify the prefix of filenames to be saved.
res_prefix_cat = "males50s_Cat"
# Run elbow, silhouette, and gap methods to find an optimum K (number of clusters).
# Do not alter the name of the input file: kmeans_input. This function below assumes that
# the input is named as "kmeans_input".
# You can only run those three methods for K = 1 through (number of observations - 1).
# The gap method output will be printed on the Console. The gap values are plotted in
# xxx_gapmethod.pdf.
ChooseK(out.dir= res_dir_cat, out.prefix= res_prefix_cat)
# With specific K values in mind, perform k-means analysis with one specified K.
# Also, change the file name to be saved as a PDF.
OneK(myK= 8, out.dir= res_dir_cat, out.fn = "males50s_Cat_K8")
# Or try multiple Ks and print the biplots in one panel.
# Likewise, change the file name to be saved as a PDF as necessary.
# This uses the factoextra and gridExtra packages.
MultipleK(myKs = c(3,4,5,6), out.dir = res_dir_cat, out.fn = "males50s_Cat_K3-6")
# Your input data should be a data frame with variables with non-zero variance.
cat_kmeansinput <- read.table("males50s_QCtotal_d_glu_body_meta_demo_Cat_rv.txt",
sep="\t", header=T)
# Ensure your input file has the correct number of rows and columns.
dim(cat_kmeansinput)
# --------------------------------------------------------------------------------------------------------------
# Come back to the main directory
setwd(main_wd)
# Load source scripts
source("lib/specify_data_dir.R")
source("lib/viz_food_tree.r")
# Specify where the data is.
SpecifyDataDirectory("eg_data/NHANES/Laboratory_data/Foodtree")
# Load your tree object.
tree <- read.tree("Food_D12_FC_cc_f_males50s_red_Lv4.nwk")
# Prepare the tree data for visualization.
PrepFoodTreePlots(input.tree=tree)
# Create a color-coded and annotated food tree with 9 L1 levels.
# Choose either 'circular' or 'radial' for layout.
# It is OK to see some warning messages about Coordinate system and scale for 'y' already being present.
VizFoodTree(input.tree=tree, layout="radial")
# Take a look at the tree.
annotated_tree
# Save.
ggsave("Food_D12_FC_cc_f_males50s_red_Lv4_viz.pdf", annotated_tree,
device="pdf", width=5.2, height=5)

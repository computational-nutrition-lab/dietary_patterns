linetype="dashed") + no_grid +
scale_color_manual(values = distinct100colors)
# Plot points and lines separately.  Specify your "y" twice.
# The geom_line function only connects the data of individuals with all days of data.
ggplot() +
geom_point(tot_m_QCed,          mapping = aes(x=RecallNo, y=TFAT, group=UserName, color=UserName)) +
geom_line( tot_m_QCed_fullonly, mapping = aes(x=RecallNo, y=TFAT, group=UserName, color=UserName),
linetype="dashed") + no_grid +
scale_color_manual(values = distinct100colors)
# ---------------------------------------------------------------------------------------------------------------
# Come back to the main directory before you start running another script.
setwd(main_wd)
# Import source code to run the analyses to follow.
source("lib/specify_dir_and_check_col.R")
source("lib/percent_kcal.R")
# Call color palette.
distinct100colors <- readRDS("lib/distinct100colors.rda")
# Load example totals data
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/")
# Load the totals data.
totals <- read.table("VVKAJ_Tot_m_QCed.txt",  sep = "\t", header = T)
# --------------------------------------------------------------------------------------------------------------
# Calculate the mean and SD of CARB, PROT, and TFAT.
CPTgramsPerUser(inputfn= totals, user.name = "UserName", recall.no = "RecallNo",
outfn='VVKAJ_Tot_m_QCed_CPT_g.txt')
# Calculate the mean % of energy intake (kcal) and SD of CARB, PROT, and TFAT.
CPTpctKcalPerUser(inputfn=totals, user.name='UserName', recall.no='RecallNo',
outfn="VVKAJ_Tot_m_QCed_CPT_kcal.txt")
# Load the %kcal values
CPT_kcal <- read.table("VVKAJ_Tot_m_QCed_CPT_kcal.txt", sep="\t", header=T)
CPT_kcal
CPT_kcal
# --------------------------------------------------------------------------------------------------------------
# Define ggplot2 themes
library(ggplot2)
# Theme black and white, with the base font size 14: change if necessary.
theme_set(theme_bw(base_size = 14))
# --------------------------------------------------------------------------------------------------------------
# Plot a barchart without SD.
# Change the font size if necessary.
stacked_wo_SD <- StackedwoSD(data= CPT_kcal) + theme(axis.text.x=element_text(size=11))
stacked_wo_SD
# --------------------------------------------------------------------------------------------------------------
# Plot the "dodge"-type of barchart (3 bars per user, NOT STACKED).
# Change the font size if necessary.
dodgedtypebarchart <- DodgedBarchart(data= CPT_kcal) + theme(axis.text.x=element_text(size=11))
# --------------------------------------------------------------------------------------------------------------
# Plot the "dodge"-type of barchart (3 bars per user, NOT STACKED).
# Change the font size if necessary.
dodgedtypebarchart <- DodgedBarchart(data= CPT_kcal) + theme(axis.text.x=element_text(size=11))
dodgedtypebarchart
# Create a vector that contains all the users (individuals).
individuals <- unique(CPT_kcal$UserName)
# Calculate sd_base and sd_forstacked for stacked barchart.
# Note that this function assumes all users (individuals) have CARB, PROT, and TFAT values.
CalcStackedSD(input.df = CPT_kcal, out.fn = "CPT_kcal_forstacked.txt")
# Load the saved file that has SD for stacked barchart.
CPT_kcal_forstacked_read <- read.table("CPT_kcal_forstacked.txt", sep="\t", header=T)
# Stacked barchart with SD as error bars.
stacked_with_SD <- StackedWithSD(data=CPT_kcal_forstacked_read) + theme(axis.text.x=element_text(size=11))
stacked_with_SD
# You can also change the breakpoints in the Y axis.
stacked_with_SD + scale_y_continuous(breaks = c(0, 20, 40, 60, 80, 100))
# Come back to the main directory
setwd(main_wd)
# Import source code to run the analyses to follow.
source("lib/specify_dir_and_check_col.R")
source("lib/prep_data_for_clustering.R")
# ---------------------------------------------------------------------------------------------------------------
# Specify the directory where the data is.
# SpecifyDataDirectory(directory.name = "eg_data/dietstudy/")
SpecifyDataDirectory(directory.name= "eg_data/VVKAJ/")
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_Tot_m_QCed.txt", sep = "\t", header = T)
# Define your input dataset (may not be necessary, but keeping this because I'm not
# sure how totals_selected are made. I think it's the same as totals_QC, though.)
totals_selected <- totals
# Subset nutrients data.
# The columns specified as start.col, end.col, and all columns in between will be selected.
# Nutrients analysis --> start.col = "PROT",  end.col = "B12_ADD", 64 variables in total.
SubsetColumns(data = totals_selected, start.col = "PROT", end.col = "B12_ADD")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var, min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the selected_variables as a .txt file. This will be the input for clustering analyses.
write.table(x=selected_variables, file="VVKAJ_Tot_m_QCed_Nut_asis.txt", sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation by using
# the CollapseByCorrelation function.
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_Tot_m_QCed_Nut_asis_corr_matrix.txt")
# ===============================================================================================================
# NUTRIENTS: Take average of each user across all days
# ===============================================================================================================
# Specify the data to be used, category to group by, and the range of columns (variables)
# to calculate the means of each variable.
# Nutrients analysis  --> start.col = "PROT",    end.col = "B12_ADD"
AverageBy(data= totals_selected, by= "UserName", start.col= "PROT", end.col= "B12_ADD")
# Save the averaged results.
write.table(x=meansbycategorydf, "VVKAJ_Tot_m_QCed_Nut_ave_allvar.txt", sep="\t", row.names=F, quote=F)
# The column names should be the same as start.col-end.col.
colnames(meansbycategorydf)
# The 'UserName' column has the users to calculate means for.
meansbycategorydf$UserName
# Pick up only the columns with non-zero variance, in order to run PCA and cluster analysis etc.
# The removed columns will be shown if any.
# [,-1] is to exclude the UserName columns that is not numeric and not used for variance calculation.
KeepNonZeroVarColumns(data = meansbycategorydf[, -1])
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var, min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the selected_variables as a .txt file. This will be the input for clustering analyses.
write.table(x=selected_variables, file="VVKAJ_Tot_m_QCed_Nut_ave_subset.txt", sep="\t", row.names=F, quote=F)
dim( selected_variables)
# ---------------------------------------------------------------------------------------------------------------
# Save the selected_variables as a .txt file. This will be the input for clustering analyses.
write.table(x=selected_variables, file="VVKAJ_Tot_m_QCed_Nut_ave_subset.txt", sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation by using
# the CollapseByCorrelation function.
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_Tot_m_QCed_Nut_ave_corr_matrix.txt")
# ===============================================================================================================
# FOOD CATEGORIES: Use data as is.
# ===============================================================================================================
# Subset food items data.
# The columns specified as start.col, end.col, and all columns in between will be selected.
# Food items analysis --> start.col = "F_TOTAL", end.col = "A_DRINKS", 37 varialbes in total.
SubsetColumns(data = totals_selected, start.col = "F_TOTAL", end.col = "A_DRINKS")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var, min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the selected_variables as a .txt file. This will be the input for clustering analyses.
write.table(x=selected_variables, file="VVKAJ_Tot_m_QCed_Cat_asis.txt", sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation by using
# the CollapseByCorrelation function.
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_Tot_m_QCed_Cat_asis_corr_matrix.txt")
# ===============================================================================================================
# FOOD CATEGORIES: Take average of each user across all days
# ===============================================================================================================
# Specify the data to be used, category to group by, and the range of columns (variables)
# to calculate the means of each variable.
# Food items analysis --> start.col = "F_TOTAL", end.col = "A_DRINKS"
AverageBy(data= totals_selected, by= "UserName", start.col= "F_TOTAL", end.col= "A_DRINKS")
# Save the averaged results.
write.table(x=meansbycategorydf, "VVKAJ_Tot_m_QCed_Cat_ave_allvar.txt", sep="\t", row.names=F, quote=F)
# The column names should be UserName + start.col-end.col.
colnames(meansbycategorydf)
# The 'UserName' column has the users to calculate means for.
meansbycategorydf$UserName
# Pick up only the columns with non-zero variance, in order to run PCA and cluster analysis etc.
# The removed columns will be shown if any.
# [,-1] is to exclude the UserName columns that is not numeric and not used for variance calculation.
KeepNonZeroVarColumns(data = meansbycategorydf[, -1])
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var, min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the selected_variables as a .txt file. This will be the input for clustering analyses.
write.table(x=selected_variables, file="VVKAJ_Tot_m_QCed_Cat_ave_subset.txt", sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation by using
# the CollapseByCorrelation function.
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_Tot_m_QCed_Cat_ave_corr_matrix.txt")
# ===============================================================================================================
# Come back to the main directory
setwd(main_wd)
# Name your main directory for future use.
main_wd <- file.path(getwd())
# Come back to the main directory
setwd(main_wd)
# Import source code to run the analyses to follow.
# source("lib/specify_dir_and_check_col.R")
# source("lib/prep_data_for_clustering.R")
source("lib/PCA.R")
# Define ggplot themes to use in creating plots.
library(ggplot2)
theme_set(theme_bw(base_size = 14))
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/")
# Load Nut_asis data.
Tot_m_QCed_Nut_asis <- read.table(file="VVKAJ_Tot_m_QCed_Nut_asis.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Nut_asis
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Specify the directory (folder) to save the results.
res_dir = "Nut_asis_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Nut_asis"
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix )
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix )
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_Tot_m_QCed.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)
# PerformPCA function to create and save PCA plots and outputs all at once.
PerformPCA <- function(pca.data=pca_input, pca.result=scaled_pca, out.dir, out.prefix){
# Create a scree plot.
screep <<- LineScreePlot(pca.data = pca_input, pca.result = scaled_pca)
# Save your plot
ggsave( paste(out.dir, paste(out.prefix, "_scree.pdf", sep=""),   sep= .Platform$file.sep),
screep, device="pdf", width=5, height=5, units="in")
# Create a biplot.
# A biplot with the individuals as black dots and variables labelled.
biplotdots <<- BiplotDots(pca.result = scaled_pca, pca.data = pca_input, alpha = 0.5)
# Save your plot
ggsave( paste(out.dir, paste(out.prefix, "_biplotdots.pdf"), sep= .Platform$file.sep),
biplotdots, device="pdf", width=5, height=5, units="in")
# Create a biplot with the individuals labeled.
biplotlabeled <- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=T)
ggsave( paste(out.dir, paste(out.prefix, "_biplotlabeled.pdf"), sep= .Platform$file.sep),
biplotlabeled, device="pdf", width=5, height=5, units="in")
# Create a biplot with the individuals labeled without the variables' arrows.
biplotlabeledwoarrows <<- BiplotLabeledwoArrows(pca.result=scaled_pca, pca.data=pca_input, individuals.label=T)
ggsave( paste(out.dir, paste(out.prefix, "_biplotlabeledwoarrows.pdf"), sep= .Platform$file.sep),
biplotlabeledwoarrows, device="pdf", width=5, height=5, units="in")
# Plot the directions of the variables.
directions <<- BiplotLabeled(pca.result=scaled_pca, pca.data=pca_input, individuals.label=F)
ggsave( paste(out.dir, paste(out.prefix, "_directions.pdf"), sep= .Platform$file.sep),
directions, device="pdf", width=5, height=5, units="in")
# Plot the contribution of the variables to a given PC: PC1 here.
loadings_plot_PC1 <<- LoadingsPlot(pca.result=scaled_pca,  whichPC="PC1",
positive.color="green2", negative.color="grey70", sort.variables = T)
ggsave( paste(out.dir, paste(out.prefix, "_loadings_PC1.pdf"), sep= .Platform$file.sep),
loadings_plot_PC1, device="pdf", width=8, height=4.8, units="in")
# Plot the contribution of the variables to a given PC: PC2 here.
loadings_plot_PC2 <<- LoadingsPlot(pca.result=scaled_pca,  whichPC="PC2",
positive.color="green2", negative.color="grey70", sort.variables = T)
ggsave( paste(out.dir, paste(out.prefix, "_loadings_PC2.pdf"), sep= .Platform$file.sep),
loadings_plot_PC2, device="pdf", width=8, height=4.8, units="in")
# ---------------------------------------------------------------------------------------------------------------
# Save the variance explained by each PC as a .txt file.
# Extract the importance of the PCs
pca_summary <- summary(pca.result)
# # Extract the Proportion of Variance
var_explained_values <- pca_summary[["importance"]][2, ]
# Create a dataframe that has the PCs and their importance (var explained by each PC)
var_explained_df <- data.frame(PC = seq(1:length(var_explained_values)),
var_explained = var_explained_values)
write.table(var_explained_df,
paste(out.dir, paste(out.prefix, '_PC_var_explained.txt'), sep= .Platform$file.sep),
sep = "\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Calculate loadings of each PC to the variables and save it as a txt file.
p <- pca.result[["rotation"]]
p <- as.data.frame(scaled_pca[["rotation"]])
# make a variable column.
variables <- rownames(p)
p$Var <- variables
# Sort the columns so that the rownames (variable names) come first
sortedp <- p[, c(length(colnames(p)), 1:length(colnames(p))-1)]
write.table(sortedp,
paste(out.dir, paste(out.prefix, '_PC_loadings.txt'), sep= .Platform$file.sep),
sep = "\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# # Probably better to run this function separately because it may be confusing as it uses the totals or averaged
#    # data as 'input', not the one processed for clustering (because the processed ones do not have all the variables;
#    # some variables are filtered out.)
#
#    # Obtain PC values and save as a txt file together with input file (before processing for clustering.)
#
#      # Define your food input file from which you derived the input for the PCA.
#      pca_input <- read.table(input, sep="\t", header=T)
#      # This has food codes and food names.
#
#      # extract the PCs
#      PCs <- as.data.frame(pca.result[["x"]])
#
#      # These should have the same number of rows, so their difference should be zero.
#      diff <- nrow(pca_input) - nrow(PCs)
#
#      # Gives an error message if the input and pca.result have a different number of rows.
#      if(diff != 0){
#
#        cat("Error: The input and the PCA results should have the same number of samples.")
#
#      }else{
#
#      # Add columns
#      Input_PCs <- cbind(pca_input, PCs)
#
#      # Save as a txt file.
#      write.table(Input_PCs,
#                  paste(out.dir, paste(out.prefix, '_input&PC.txt'), sep= .Platform$file.sep),
#                  sep="\t", row.names = F, quote = F)
#      }
}
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix )
# Come back to the main directory
setwd(main_wd)
# Import source code to run the analyses to follow.
# source("lib/specify_dir_and_check_col.R")
# source("lib/prep_data_for_clustering.R")
source("lib/PCA.R")
theme_set(theme_bw(base_size = 14))
theme_set(theme_bw(base_size = 14))
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/")
# Load Nut_asis data.
Tot_m_QCed_Nut_asis <- read.table(file="VVKAJ_Tot_m_QCed_Nut_asis.txt", sep="\t", header=T)
# Name your input data.
pca_input <- Tot_m_QCed_Nut_asis
# Ensure your input file has the correct number of rows and columns.
dim(pca_input)
# Perform PCA with the subset data, scaled.
scaled_pca <- prcomp(x=pca_input, scale = TRUE)
# Specify the directory (folder) to save the results.
res_dir = "Nut_asis_PCA"
# Specify the prefix of filenames to be saved.
res_prefix = "VVKAJ_Nut_asis"
# Perform PCA and save the results in a specified folder (out.dir) and a prefix (out.prefix).
PerformPCA(pca.data=pca_input, pca.result=scaled_pca, out.dir= res_dir, out.prefix= res_prefix )
# Combine the input (totals before processing) with all the variables and the PC results.
SaveInputAndPCs(input="VVKAJ_Tot_m_QCed.txt", pca.results = scaled_pca,
out.dir= res_dir, out.prefix= res_prefix)
# Load the PCA result
pcares <- read.table("Nut_asis_PCA/VVKAJ_Nut_asis_PCs.txt", sep="\t", header=T)
head(pcares)
# Create a biplot with the users colored by different metadata.
# By gender
ggplot(pcares, aes(x=PC1, y=PC2)) +
geom_point()
# Create a biplot with the users colored by different metadata.
# By Diet
meta
# Create a biplot with the users colored by different metadata.
# By Diet
metadata_diet <- read.table("clipboard", sep="\t", header=T)
metadata_diet
pcares$UserName
merge(pcares, metadata_diet, all.x=T)
pcares_diet <- merge(pcares, metadata_diet, all.x=T)
colnames(pcares_diet)
#
ggplot(pcares_diet, aes(x=PC1, y=PC2), fill=Diet, color=Diet) +
geom_point()
#
ggplot(pcares_diet, aes(x=PC1, y=PC2)) +
geom_point(fill=Diet, color=Diet)
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point()
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors)
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = "black")
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color='black', fill=Diet)) +
geom_point(size=3) +
scale_fill_manual(values = distinct100colors)
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors)
head(pcares,1)
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
no_grid + space_axes +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors) +
scale_x_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of X (to fit text).
scale_y_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of Y (to fit text).
# ---------------------------------------------------------------------------------------------------------------
autoplot(object = pcares, data = pca.data,
label = individuals.label, label.size = 3, shape =FALSE,
loadings = T, loadings.label = T, loadings.colour = 'pink',
loadings.label.size=3) +
scale_x_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of X (to fit text).
scale_y_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of Y (to fit text).
theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank()) +
theme(axis.title.x = element_text(margin=margin(t = 10, r = 0, b = 0, l = 0) ) ) +
theme(axis.title.y = element_text(margin=margin(t = 0, r = 10, b = 0, l = 0) ) ) +
theme(aspect.ratio = 1)
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
no_grid + space_axes +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors) +
scale_x_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of X (to fit text).
scale_y_continuous(expand = expansion(mult=c(0.1, 0.1)))   # give some space on the lower and the upper limits of Y (to fit text).
# ---------------------------------------------------------------------------------------------------------------
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/")
# ---------------------------------------------------------------------------------------------------------------
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/Nut_asis_PCA")
# Load the PCA result
pcares <- read.table("VVKAJ_Nut_asis_PCs.txt", sep="\t", header=T)
head(pcares,1)
PC_var_exp <- read.table("VVKAJ_Nut_asis_PC_var_explained.txt", sep="\t", header=T)
head(PC_var_exp)
PC_var_exp[1,2]
PC_var_exp
head(PC_var_exp)
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
no_grid + space_axes +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors) +
scale_x_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of X (to fit text).
scale_y_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of Y (to fit text).
labs(x = paste("PC1 (", round(PC_var_exp[1,2], 1), "%)", sep=""),
y = paste("PC2 (", round(PC_var_exp[2,2], 2), "%)", sep=""))
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
no_grid + space_axes +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors) +
scale_x_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of X (to fit text).
scale_y_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of Y (to fit text).
labs(x = paste("PC1 (", round(PC_var_exp[1,2]*100, 1), "%)", sep=""),
y = paste("PC2 (", round(PC_var_exp[2,2]*100, 2), "%)", sep=""))
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
no_grid + space_axes +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors) +
scale_x_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of X (to fit text).
scale_y_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of Y (to fit text).
labs(x = paste("PC1 (", round(PC_var_exp[1,2]*100, 1), "%)", sep=""),
y = paste("PC2 (", round(PC_var_exp[2,2]*100, 1), "%)", sep=""))
#
ggplot(pcares_diet, aes(x=PC1, y=PC2, color=Diet, fill=Diet)) +
geom_point(size=3) +
no_grid + space_axes +
scale_fill_manual(values = distinct100colors) +
scale_color_manual(values = distinct100colors) +
scale_x_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of X (to fit text).
scale_y_continuous(expand = expansion(mult=c(0.1, 0.1))) + # give some space on the lower and the upper limits of Y (to fit text).
labs(x = paste("PC1 (", round(PC_var_exp[1,2]*100, 2), "%)", sep=""),
y = paste("PC2 (", round(PC_var_exp[2,2]*100, 2), "%)", sep=""))

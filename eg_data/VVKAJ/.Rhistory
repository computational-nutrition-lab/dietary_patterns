bbb = as.data.frame(table(mycol))
bbb
sortedbbb = bbb[ order(bbb$Freq, decreasing = T), ]
sortedbbb
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
# NUMERIC ----
bbb = as.data.frame(table(mycol))
bbb
colnames(bbb)
sortedbbb = bbb[ order(bbb$Freq, decreasing = T), ]
sortedbbb
write.table(as.data.frame(sortedbbb), "clipboard", sep="\t")
install.packages("wordcloud")
library(wordcloud)
library(RColorBrewer)
install.packages("tm")
library(tm)
#Create a vector containing only the text
text <- data$text
install.packages("wordcloud2")
library(wordcloud2)
#Create a vector containing only the text
text <- data$text
View(bbb)
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 400, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 400, random.order=FALSE, rot.per=0.8,
colors=brewer.pal(8, "Dark2"))
?wordcloud
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 400, random.order=T, rot.per=1,
colors=brewer.pal(8, "Dark2"))
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 400, random.order=T, rot.per=0,
colors=brewer.pal(8, "Dark2"))
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"))
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 40, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"))
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 40, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
head(sortedbbb)
head(sortedbbb,15)
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 40, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F, ordered.colors=T)
wordcloud(words=sortedbbb$mycol, freq=sortedbbb$Freq, min.freq=5,
max.words = 40, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
head(sortedbbb,15)
View(sortedbbb)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=5,
max.words = 40, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=5,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=10,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=20,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=20,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=T)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=15,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=30,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=5,
max.words = 400, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud(words=bbb$mycol, freq=bbb$Freq, min.freq=5,
max.words = 100, random.order=F, rot.per=0,
colors=brewer.pal(8, "Dark2"), fixed.asp=F)
wordcloud2(data=bbb, size=1.6, color='random-dark')
head(sortedbbb,15)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
# NUMERIC ----
bbb = as.data.frame(table(mycol))
bbb
colnames(bbb)
sortedbbb = bbb[ order(bbb$Freq, decreasing = T), ]
sortedbbb
write.table(as.data.frame(sortedbbb), "clipboard", sep="\t", row.names=F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
# NUMERIC ----
bbb = as.data.frame(table(mycol))
bbb
sortedbbb = bbb[ order(bbb$Freq, decreasing = T), ]
sortedbbb
head(sortedbbb)
write.table(as.data.frame(sortedbbb), "clipboard", sep="\t", row.names=F)
female = read.table(file="clipboard", sep="\t", header=T)
head(female, 20)
nrow(female)
male = read.table(file="clipboard", sep="\t", header=T)
head(male, 20)
nrow(male)
names(female)
names(female)[2] <- "female_freq"
nrow(female)
head(female, 20)
names(male)[2] <- "male_freq"
head(male, 20)
fandm <- merge(x=female, y=male, all = T, by="mycol")
head(fandm)
ttwoway <- fandm
Total = colSums(t(ttwoway)) # Column totals
fandm_zeros[ is.na(fandm_zeros) ] <- 0
fandm_zeros <- fandm # make a copy
fandm_zeros[ is.na(fandm_zeros) ] <- 0
head(fandm_zeros)
ttwoway <- fandm_zeros
Total = colSums(t(ttwoway)) # Column totals
write.table(fandm_zeros, "clipboard", sep='\t')
write.table(fandm_zeros, "clipboard", sep='\t', row.names = F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
# NUMERIC ----
bbb = as.data.frame(table(mycol))
bbb
sortedbbb = bbb[ order(bbb$Freq, decreasing = T), ]
sortedbbb
table(sortedbbb$Freq)
sum(sortedbbb$Freq)
write.table(as.data.frame(sortedbbb), "clipboard", sep="\t", row.names=F)
colnames(bbb)
bbb
write.table(bbb, "clipboard", sep="\t", row.names = F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
# NUMERIC ----
bbb = as.data.frame(table(mycol))
bbb
write.table(bbb, "clipboard", sep="\t", row.names = F)
nrow(mycol)
head(mycol, 20)
unique(mycol)
uniquenames = unique(mycol)
write.table(uniquenames, "clipboard", sep="\t", row.names = F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
uniquenames = unique(mycol)
sort(uniquenames)
order(uniquenames)
uniquenames
write.table(uniquenames, "clipboard", sep="\t", row.names = F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
# NUMERIC ----
bbb = as.data.frame(table(mycol))
bbb
write.table(bbb, "clipboard", sep="\t", row.names = F)
# Useful! Get counts of data from Excel =========================================================
# Get data (One column) from Clipboard ================================================
mycol = read.table(file="clipboard", sep=",") # sep="," for 1 column, sep="\t" for multiple columns
head(mycol, 20)
nrow(mycol)
# Freq table with 2 variables.===========================================================
mydata = read.table(file="clipboard", sep="\t", header =T) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
mydata = read.table(file="clipboard", sep="\t", header =f) # sep="," for 1 column, sep="\t" for multiple columns
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
V1table = as.data.frame(table(mydata$V1))
write.table(V1table, "clipboard", sep="\t", row.names = F)
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
V1table = as.data.frame(table(mydata$V1))
V1table
sortedV1table = V1table[ order(V1table$Freq, decreasing = T), ]  # sort by col totals
sortedV1table
write.table(sortedV1table, "clipboard", sep="\t", row.names = F)
length(unique(mydata$V1))
write.table(V1table, "clipboard", sep="\t", row.names = F)
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
V1table = as.data.frame(table(mydata$V1))
write.table(V1table, "clipboard", sep="\t", row.names = F)
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
V1table = as.data.frame(table(mydata$V1))
V1table
length(unique(mydata$V1))
write.table(V1table, "clipboard", sep="\t", row.names = F)
sortedV1table = V1table[ order(V1table$Freq, decreasing = T), ]  # sort by col totals
write.table(sortedV1table, "clipboard", sep="\t", row.names = F)
# generate a two-way parents' frequency table
female = read.table(file="clipboard", sep="\t", header=T)
head(female, 20)
nrow(female)
# generate a two-way parents' frequency table
female = read.table(file="clipboard", sep="\t", header=F)
head(female, 20)
nrow(female)
names(female)
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
V1table = as.data.frame(table(mydata$V1))
write.table(V1table, "clipboard", sep="\t", row.names = F)
sortedV1table = V1table[ order(V1table$Freq, decreasing = T), ]  # sort by col totals
write.table(sortedV1table, "clipboard", sep="\t", row.names = F)
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
V1table = as.data.frame(table(mydata$V1))
write.table(V1table, "clipboard", sep="\t", row.names = F)
sortedV1table = V1table[ order(V1table$Freq, decreasing = T), ]  # sort by col totals
write.table(sortedV1table, "clipboard", sep="\t", row.names = F)
# generate a two-way parents' frequency table
female = read.table(file="clipboard", sep="\t", header=F)
head(female, 20)
nrow(female)
# generate a two-way parents' frequency table
female = read.table(file="clipboard", sep="\t", header=F)
head(female, 20)
nrow(female)
names(female)[2] <- "female_freq"
male = read.table(file="clipboard", sep="\t", header=T)
head(male, 20)
nrow(male)
nrow(male)
names(male)[2] <- "male_freq"
head(female, 20)
# generate a two-way parents' frequency table
female = read.table(file="clipboard", sep="\t", header=T)
head(female, 20)
nrow(female)
names(female)[2] <- "female_freq"
head(female, 20)
head(male, 20)
fandm <- merge(x=female, y=male, all = T, by="Val1")
fandm <- merge(x=female, y=male, all = T, by="Var1")
head(fandm)
# replace NAs with zero.
fandm_zeros[ is.na(fandm_zeros) ] <- 0
fandm_zeros <- fandm # make a copy
# replace NAs with zero.
fandm_zeros[ is.na(fandm_zeros) ] <- 0
head(fandm_zeros)
write.table(fandm_zeros, "clipboard", sep='\t', row.names = F)
ttwoway <- fandm_zeros
Total = colSums(t(ttwoway)) # Column totals
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
V1table = as.data.frame(table(mydata$V1))
write.table(V1table, "clipboard", sep="\t", row.names = F)
sortedV1table = V1table[ order(V1table$Freq, decreasing = T), ]  # sort by col totals
write.table(V1table, "clipboard", sep="\t", row.names = F)
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
mydata = read.table(file="clipboard", sep="\t", header =F) # sep="," for 1 column, sep="\t" for multiple columns
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
tail(mydata)
nrow(mydata)
library(dplyr)
# write.table(mycol, "clipboard", sep="\t")
# mydata
head(mydata)
mydata %>% group_by(V2) %>% summarize(totalcount=count(V4))
mydata %>% group_by(V2) %>% summarise(totalcount=sum(V4))
bypulse <-  mydata %>% group_by(V2) %>% summarise(totalcount=sum(V4))
write.table(bypulse, "clipboard", sep='\t')
setwd("~/GitHub/dietary_patterns")
# Name your main directory for future use.
main_wd <- file.path(getwd())
# ========================================================================================
# Load source scripts
# ========================================================================================
source("lib/specify_dir_and_check_col.R")
# Come back to the main directory
setwd(main_wd)
# ========================================================================================
# Load source scripts
# ========================================================================================
source("lib/specify_dir_and_check_col.R")
source("lib/Food_tree_scripts/newick.tree.r")
source("lib/Food_tree_scripts/check.db.r")
source("lib/Food_tree_scripts/format.foods.r")
source("lib/Food_tree_scripts/filter.db.by.diet.records.r")
source("lib/Food_tree_scripts/make.food.tree.r")
source("lib/Food_tree_scripts/make.food.otu.r")
source("lib/Food_tree_scripts/make.fiber.otu.r")
source("lib/Food_tree_scripts/make.dhydrt.otu.r")
# Current ASA24 database doesn't have modcodes, so de-duplicate database file,
# replace special characters with "_", and create a new FoodID out of foodcode and modcode.
# It leaves all other columns intact.
FormatFoods(input_fn="data/Food_tree_data/all.food.desc.txt", output_fn="data/Food_tree_data/ASA24Database.txt")
# FoodCode and Main.food.description of additional foods not in ASA24. Format it for use.
FormatFoods(input_fn="data/Food_tree_data/Soylent_codes.txt", output_fn="data/Food_tree_data/Soylent_codes_formatted.txt")
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/")
# Format your items data, and save the formatted items file to the "Foodtree" folder.
FormatFoods(input_fn="VVKAJ_Items_f_s_m.txt", output_fn="Foodtree/VVKAJ_Items_f_s_m_ff.txt", dedupe=F)
# Come back to the main directory for now.
setwd(main_wd)
# Generate a tree with the whole ASA24 food database first.
# if there are missing foods, then create new files to add them in below under addl_foods
MakeFoodTree(nodes_fn=        "data/Food_tree_data/NodeLabelsMCT.txt",
food_database_fn="data/Food_tree_data/ASA24Database.txt",
addl_foods_fn= c("data/Food_tree_data/Soylent_codes_formatted.txt"),
num.levels = 4,  # How many levels of foods to be classified
output_taxonomy_fn = "Food_tree_ASA24/ASA24_Lv4.taxonomy.txt",  # Name your output taxonomy file
output_tree_fn=      "Food_tree_ASA24/ASA24_Lv4.tree.nwk"       # Name your output tree
)
# Generate a tree with the whole ASA24 food database first.
# if there are missing foods, then create new files to add them in below under addl_foods
MakeFoodTree(nodes_fn=        "data/Food_tree_data/NodeLabelsMCT.txt",
food_database_fn="data/Food_tree_data/ASA24Database.txt",
addl_foods_fn= c("data/Food_tree_data/Soylent_codes_formatted.txt"),
num.levels = 4,  # How many levels of foods to be classified
output_taxonomy_fn = "data/Food_tree_ASA24/ASA24_Lv4.taxonomy.txt",  # Name your output taxonomy file
output_tree_fn=      "data/Food_tree_ASA24/ASA24_Lv4.tree.nwk"       # Name your output tree
)
# Specify the directory where the data is again.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/Foodtree")
# Limit to just the foods reported in your study (formatted dietrecords.txt as the input)
FilterDbByDietRecords(food_database_fn = "../../../data/Food_tree_data/ASA24Database.txt",
food_records_fn  = "VVKAJ_Items_f_s_m_ff.txt",   # output of FormatFoods above.
output_fn        = "VVKAJ_Items_f_s_m_ff_database.txt")
# make a food tree with the reduced data.
MakeFoodTree(nodes_fn=         "../../../data/Food_tree_data/NodeLabelsMCT.txt",
food_database_fn= "VVKAJ_Items_f_s_m_ff_database.txt",    # output for FilterDbByDietRecords above.
addl_foods_fn   = NULL,
num.levels      = 4,
output_taxonomy_fn = "VVKAJ_Items_f_s_m_ff_reduced_4Lv.tax.txt",
output_tree_fn=      "VVKAJ_Items_f_s_m_ff_reduced_4Lv.tree.nwk"
)
# ---------------------------------------------------------------------------------------------------------------
# Generate standard, grams of fiber, and dehydrated grams per kcal OTU tables to be used later.
# Make the standard food otu table with data in gram weights of food.
MakeFoodOtu(food_records_fn=  "VVKAJ_Items_f_s_m_ff.txt",
food_record_id =  "UserName",                       # Specify the ID of your participants
food_taxonomy_fn= "VVKAJ_Items_f_s_m_ff_reduced_4Lv.tax.txt",  # Specify your taxonomy file produced by MakeFoodTree.
output_fn =       "VVKAJ_Items_f_s_m_ff_reduced_4Lv.food.otu.txt")  # Name your output otu file.
# Make a food otu table with data in grams of fiber per food
MakeFiberOtu(food_records_fn=  "VVKAJ_Items_f_s_m_ff.txt",
food_record_id=   "UserName",
food_taxonomy_fn= "VVKAJ_Items_f_s_m_ff_reduced_4Lv.tax.txt",
output_fn=        "VVKAJ_Items_f_s_m_ff_reduced_4Lv.fiber.otu.txt")
# Make a food otu table as dehydrated grams per kcal.
MakeDhydrtOtu(food_records_fn=  "VVKAJ_Items_f_s_m_ff.txt",
food_record_id =  "UserName",
food_taxonomy_fn= "VVKAJ_Items_f_s_m_ff_reduced_4Lv.tax.txt",
output_fn =       "VVKAJ_Items_f_s_m_ff_reduced_4Lv.dhydrt.otu.txt")
# Make a food otu table as dehydrated grams per kcal.
MakeDhydrtOtu(food_records_fn=  "VVKAJ_Items_f_s_m_ff.txt",
food_record_id =  "UserName",
food_taxonomy_fn= "VVKAJ_Items_f_s_m_ff_reduced_4Lv.tax.txt",
output_fn =       "VVKAJ_Items_f_s_m_ff_reduced_4Lv.dhydrt.otu.txt")
# ---------------------------------------------------------------------------------------------------------------
# use this working directory until this script is complete.
setwd("~/GitHub/dietary_patterns")
# Load the functions necessary to set directories.
source("lib/specify_dir_and_check_col.R")
# ========================================================================================
# Load source scripts for visualizing food trees.
# ========================================================================================
source("lib/viz_food_tree.r")
# ---------------------------------------------------------------------------------------------------------------
# Prepare node labels of L1 for plotting. It assumes that the tree file has 9 L1 levels.
PrepFoodTreePlots(input.tree=tree)
# NHANES
tree <- read.tree("results/Food_tree_NHANES/NHANES1516.reduced_Lv1.tree.nwk")
# Load the generated food tree. This will load the .nwk file and save it as a tree object called “tree”.
tree <- read.tree("VVKAJ_Items_f_s_m_ff_reduced_4Lv.tree.nwk")
tree
# Go to the "Foodtree" directory where the tree files are saved.
SpecifyDataDirectory(directory.name = "eg_data/VVKAJ/Foodtree")
# Load the generated food tree. This will load the .nwk file and save it as a tree object called “tree”.
tree <- read.tree("VVKAJ_Items_f_s_m_ff_reduced_4Lv.tree.nwk")
# ---------------------------------------------------------------------------------------------------------------
# Prepare node labels of L1 for plotting. It assumes that the tree file has 9 L1 levels.
PrepFoodTreePlots(input.tree=tree)
# Create a color-coded and annotated food tree with 9 L1 levels.
# Choose either 'circular' or 'radial' for layout.
# It is OK to see some warning messages about Coordinate system and scale for 'y' already being present.
VizFoodTree(input.tree=tree, layout="radial")
# Look at the color-coded and annotated food tree, saved as annotated_tree.
annotated_tree
# Save the tree as a PDF file.
ggsave("VVKAJ_Items_f_s_m_ff_reduced_4Lv.tree.pdf", annotated_tree, device="pdf", width=6, height=6, units="in", dpi=300)
# Or a tiff file.
ggsave("VVKAJ_Items_f_s_m_ff_reduced_4Lv.tree.tif", annotated_tree, device='tiff', width=6, height=6, dpi=300)
# Or a tiff file.
ggsave("VVKAJ_Items_f_s_m_ff_reduced_4Lv.tree.png", annotated_tree, device='png', width=6, height=6, dpi=300)
# ---------------------------------------------------------------------------------------------------------------
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name= "eg_data/VVKAJ/")
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_Tot_m_QCed.txt", sep = "\t", header = T)
# Subset nutrients data.
# The columns specified as start.col, end.col, and all columns in between will be selected.
# Nutrients analysis --> start.col = "PROT",  end.col = "B12_ADD", 64 variables in total.
SubsetColumns(data = totals, start.col = "PROT", end.col = "B12_ADD")
# Come back to the main directory
setwd(main_wd)
# Import source code to run the analyses to follow.
source("lib/specify_dir_and_check_col.R")
source("lib/prep_data_for_clustering.R")
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_Tot_m_QCed.txt", sep = "\t", header = T)
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_Tot_m_QCed.txt", sep = "\t", header = T)
# ---------------------------------------------------------------------------------------------------------------
# Specify the directory where the data is.
SpecifyDataDirectory(directory.name= "eg_data/VVKAJ/")
# ASA24 data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load the totals data:
# totals <- read.table("Totals_to_use.txt", sep = "\t", header = T)
totals <- read.table("VVKAJ_Tot_m_QCed.txt", sep = "\t", header = T)
# Subset nutrients data.
# The columns specified as start.col, end.col, and all columns in between will be selected.
# Nutrients analysis --> start.col = "PROT",  end.col = "B12_ADD", 64 variables in total.
SubsetColumns(data = totals, start.col = "PROT", end.col = "B12_ADD")
# Pick up only the columns with non-zero variance, in order to run PCA, cluster analysis etc.
# The removed columns will be shown if any.
KeepNonZeroVarColumns(data = subsetted)
# ---------------------------------------------------------------------------------------------------------------
# Collapse variables by correlation: take only one variables if they are highly correlated.
cbc_res <- CollapseByCorrelation(x = subsetted_non0var, min.cor = 0.75,
select.rep.fcn = 'mean', verbose = T)
# Filter out highly correlated variables from the original dataset.
selected_variables <- subsetted_non0var[, cbc_res$reps]
# Check the name of the original and filtered variables.
# Among the variables in the same group, the one with the highest variance is kept
#  (according to the explanation above.)
# filtered
head(selected_variables, 1)
dim( selected_variables)
# original
head(subsetted_non0var, 1)
dim( subsetted_non0var)
# ---------------------------------------------------------------------------------------------------------------
# Save the selected_variables as a .txt file. This will be the input for clustering analyses.
write.table(x=selected_variables, file="VVKAJ_Tot_m_QCed_Nut_asis_2.txt", sep="\t", row.names=F, quote=F)
# ---------------------------------------------------------------------------------------------------------------
# Save the correlation matrix for record in the results folder.
# cc is the correlation matrix produced when variables are collapsed by correlation by using
# the CollapseByCorrelation function.
SaveCorrMatrix(x=cc, out.fn = "VVKAJ_Tot_m_QCed_Nut_asis_corr_matrix_2.txt")
